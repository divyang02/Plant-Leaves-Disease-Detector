{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divy/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/divy/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from imagenet_utils import decode_predictions\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import math\n",
    "import time\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 38\n",
    "epochs = 2\n",
    "\n",
    "label_counter = 0\n",
    "\n",
    "label_map_dict = {}\n",
    "image_data_list = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54272\n",
      "54305\n",
      "54305\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "data_path = path + '/raw/color'\n",
    "\n",
    "for filename in os.listdir(data_path) :\n",
    "    text_filename = filename.strip()\n",
    "    for imagename in os.listdir(data_path + '/' + filename) :\n",
    "        img_path = data_path + '/' + filename + '/' + imagename\n",
    "#         img = image.load_img(img_path, target_size=(224,224))\n",
    "#         x = image.img_to_array(img)\n",
    "#         x = np.expand_dims(x, axis = 0)\n",
    "#         x = preprocess_input(x)\n",
    "        image_data_list.append(img_path)\n",
    "        labels.append(label_counter)\n",
    "        \n",
    "    if label_counter not in label_map_dict :\n",
    "        label_map_dict[label_counter] = text_filename\n",
    "    label_counter += 1\n",
    "    \n",
    "    \n",
    "nice_n = math.floor(len(image_data_list) / batch_size) * batch_size\n",
    "\n",
    "print(nice_n)\n",
    "print(len(image_data_list))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1973.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4847.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1757.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2163.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1942.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/4005fb13-0d7c-4a30-9ee3-73e9e4cee05e___RS_HL 1688.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/29050f21-a393-473e-9f9c-7fd99feef9a7___RS_HL 4533.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/a5db3b2a-9806-45c1-b1f8-9d6f414222f2___RS_HL 2067.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Strawberry___healthy/c4eca43a-adf9-4d30-a990-8b177165fb04___RS_HL 4708.JPG']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[8, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "print(image_data_list[0:9])\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(labels[8758:8766])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "perm = list(range(len(image_data_list)))\n",
    "random.shuffle(perm)\n",
    "image_data_list = [image_data_list[index] for index in perm]\n",
    "labels = [labels[index] for index in perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready.......!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Data is ready.......!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch() :\n",
    "    index = 1\n",
    "    \n",
    "    global current_index\n",
    "    \n",
    "    B = np.zeros(shape=(batch_size, 224,224,3))\n",
    "    L = np.zeros(shape=(batch_size))\n",
    "    \n",
    "    while index < batch_size :\n",
    "        try :\n",
    "            img = load_img(image_data_list[current_index], target_size = (224,224))\n",
    "            B[index] = img_to_array(img)\n",
    "            B[index] = np.expand_dims(B[index], axis = 0)\n",
    "            B[index] = preprocess_input(B[index])\n",
    "            \n",
    "            L[index] = labels[current_index]\n",
    "            \n",
    "            index += 1\n",
    "            current_index += 1\n",
    "            \n",
    "        except:\n",
    "            print(\"Ignore image {}\".format(image_data_list[current_index]))\n",
    "            current_index = current_index + 1\n",
    "\n",
    "            \n",
    "    return B, keras.utils.to_categorical(L, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Tomato___Spider_mites Two-spotted_spider_mite/8316fb24-c884-4dc0-a1d5-e84d2e8ac6eb___Com.G_SpM_FL 1383.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Orange___Haunglongbing_(Citrus_greening)/36e355b5-10c2-4250-8030-ad5c42832cfd___UF.Citrus_HLB_Lab 9703.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Tomato___Leaf_Mold/27c4fc3e-760a-4d3c-8552-bb5ca4eab3d8___Crnl_L.Mold 6781.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Peach___Bacterial_spot/5970f270-e90a-4040-aaaa-2f1b2ff8406c___Rutg._Bact.S 1665.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Soybean___healthy/1b283b99-e33d-4b1d-baf3-aa3d06305d1c___RS_HL 4286.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Corn_(maize)___Northern_Leaf_Blight/b0a2b2fe-4113-4498-9350-ef9580d7bed6___RS_NLB 3832.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Corn_(maize)___Common_rust_/RS_Rust 1690.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Soybean___healthy/f13cefbc-d264-40d5-87b7-8acfd523f922___RS_HL 6271.JPG', '/Users/divy/Desktop/plantvillage_deeplearning_paper_dataset-master/raw/color/Orange___Haunglongbing_(Citrus_greening)/f5f7ed89-f93a-4c5b-ab61-c9ee4bf7eb65___CREC_HLB 7673.JPG']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[31, 27, 37, 16, 19, 28, 14, 24]\n"
     ]
    }
   ],
   "source": [
    "print(image_data_list[0:9])\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(labels[8758:8766])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_input = Input(shape=(224,224,3))\n",
    "include_top = True\n",
    "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 38)                155686    \n",
      "=================================================================\n",
      "Total params: 134,416,230\n",
      "Trainable params: 134,416,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation = 'softmax', name = 'output')(last_layer)\n",
    "customVggModel = Model(image_input,out)\n",
    "customVggModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in customVggModel.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 38)                155686    \n",
      "=================================================================\n",
      "Total params: 134,416,230\n",
      "Trainable params: 155,686\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "customVggModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customVggModel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "batch 0/848 loss: 5.03986120223999 accuracy: 0.234375 time: 39300.28414726257ms\n",
      "63\n",
      "\n",
      "\n",
      "batch 1/848 loss: 6.888010025024414 accuracy: 0.078125 time: 37219.5839881897ms\n",
      "126\n",
      "\n",
      "\n",
      "batch 2/848 loss: 4.535662651062012 accuracy: 0.1875 time: 36688.10510635376ms\n",
      "189\n",
      "\n",
      "\n",
      "batch 3/848 loss: 4.0216875076293945 accuracy: 0.328125 time: 37571.89393043518ms\n",
      "252\n",
      "\n",
      "\n",
      "batch 4/848 loss: 2.844921112060547 accuracy: 0.296875 time: 37395.06387710571ms\n",
      "315\n",
      "\n",
      "\n",
      "batch 5/848 loss: 2.743614435195923 accuracy: 0.421875 time: 36238.11197280884ms\n",
      "378\n",
      "\n",
      "\n",
      "batch 6/848 loss: 2.8384547233581543 accuracy: 0.359375 time: 37418.14303398132ms\n",
      "441\n",
      "\n",
      "\n",
      "batch 7/848 loss: 3.012424945831299 accuracy: 0.296875 time: 40403.794050216675ms\n",
      "504\n",
      "\n",
      "\n",
      "batch 8/848 loss: 1.8441908359527588 accuracy: 0.546875 time: 37910.64810752869ms\n",
      "567\n",
      "\n",
      "\n",
      "batch 9/848 loss: 2.0349068641662598 accuracy: 0.40625 time: 35589.22100067139ms\n",
      "630\n",
      "\n",
      "\n",
      "batch 10/848 loss: 2.3285446166992188 accuracy: 0.515625 time: 36923.3181476593ms\n",
      "693\n",
      "\n",
      "\n",
      "batch 11/848 loss: 1.925553321838379 accuracy: 0.421875 time: 36166.27502441406ms\n",
      "756\n",
      "\n",
      "\n",
      "batch 12/848 loss: 1.433410406112671 accuracy: 0.671875 time: 37389.15300369263ms\n",
      "819\n",
      "\n",
      "\n",
      "batch 13/848 loss: 1.9333233833312988 accuracy: 0.53125 time: 36095.92700004578ms\n",
      "882\n",
      "\n",
      "\n",
      "batch 14/848 loss: 1.8603167533874512 accuracy: 0.53125 time: 37740.92411994934ms\n",
      "945\n",
      "\n",
      "\n",
      "batch 15/848 loss: 1.4612513780593872 accuracy: 0.59375 time: 36125.263929367065ms\n",
      "1008\n",
      "\n",
      "\n",
      "batch 16/848 loss: 1.5606083869934082 accuracy: 0.59375 time: 35905.81202507019ms\n",
      "1071\n",
      "\n",
      "\n",
      "batch 17/848 loss: 1.245065450668335 accuracy: 0.640625 time: 37176.09095573425ms\n",
      "1134\n",
      "\n",
      "\n",
      "batch 18/848 loss: 1.1233335733413696 accuracy: 0.703125 time: 35315.62089920044ms\n",
      "1197\n",
      "\n",
      "\n",
      "batch 19/848 loss: 1.1951706409454346 accuracy: 0.71875 time: 36154.6790599823ms\n",
      "1260\n",
      "\n",
      "\n",
      "batch 20/848 loss: 1.0263068675994873 accuracy: 0.765625 time: 36677.94895172119ms\n",
      "1323\n",
      "\n",
      "\n",
      "batch 21/848 loss: 1.2830464839935303 accuracy: 0.640625 time: 36163.82598876953ms\n",
      "1386\n",
      "\n",
      "\n",
      "batch 22/848 loss: 1.3494805097579956 accuracy: 0.53125 time: 36790.77386856079ms\n",
      "1449\n",
      "\n",
      "\n",
      "batch 23/848 loss: 1.4286586046218872 accuracy: 0.640625 time: 35877.93302536011ms\n",
      "1512\n",
      "\n",
      "\n",
      "batch 24/848 loss: 1.1801557540893555 accuracy: 0.71875 time: 36393.61000061035ms\n",
      "1575\n",
      "\n",
      "\n",
      "batch 25/848 loss: 0.807593584060669 accuracy: 0.75 time: 36154.083013534546ms\n",
      "1638\n",
      "\n",
      "\n",
      "batch 26/848 loss: 1.0618656873703003 accuracy: 0.59375 time: 36737.99395561218ms\n",
      "1701\n",
      "\n",
      "\n",
      "batch 27/848 loss: 0.9782806634902954 accuracy: 0.71875 time: 37165.82798957825ms\n",
      "1764\n",
      "\n",
      "\n",
      "batch 28/848 loss: 1.2957106828689575 accuracy: 0.640625 time: 37181.20789527893ms\n",
      "1827\n",
      "\n",
      "\n",
      "batch 29/848 loss: 1.3484523296356201 accuracy: 0.59375 time: 36556.621074676514ms\n",
      "1890\n",
      "\n",
      "\n",
      "batch 30/848 loss: 1.4145331382751465 accuracy: 0.515625 time: 38432.52611160278ms\n",
      "1953\n",
      "\n",
      "\n",
      "batch 31/848 loss: 1.125739574432373 accuracy: 0.6875 time: 36074.52607154846ms\n",
      "2016\n",
      "\n",
      "\n",
      "batch 32/848 loss: 0.9003683924674988 accuracy: 0.71875 time: 37172.17707633972ms\n",
      "2079\n",
      "\n",
      "\n",
      "batch 33/848 loss: 1.1057400703430176 accuracy: 0.734375 time: 36535.12120246887ms\n",
      "2142\n",
      "\n",
      "\n",
      "batch 34/848 loss: 1.333782434463501 accuracy: 0.609375 time: 37121.29306793213ms\n",
      "2205\n",
      "\n",
      "\n",
      "batch 35/848 loss: 0.9087799787521362 accuracy: 0.75 time: 36974.21884536743ms\n",
      "2268\n",
      "\n",
      "\n",
      "batch 36/848 loss: 0.7872493267059326 accuracy: 0.796875 time: 36221.98390960693ms\n",
      "2331\n",
      "\n",
      "\n",
      "batch 37/848 loss: 0.7205473184585571 accuracy: 0.78125 time: 38332.95702934265ms\n",
      "2394\n",
      "\n",
      "\n",
      "batch 38/848 loss: 0.7290948629379272 accuracy: 0.78125 time: 35760.15591621399ms\n",
      "2457\n",
      "\n",
      "\n",
      "batch 39/848 loss: 0.9446104764938354 accuracy: 0.6875 time: 36312.94107437134ms\n",
      "2520\n",
      "\n",
      "\n",
      "batch 40/848 loss: 1.1109063625335693 accuracy: 0.703125 time: 37118.958950042725ms\n",
      "2583\n",
      "\n",
      "\n",
      "batch 41/848 loss: 0.6724182963371277 accuracy: 0.8125 time: 35984.13300514221ms\n",
      "2646\n",
      "\n",
      "\n",
      "batch 42/848 loss: 0.941588282585144 accuracy: 0.703125 time: 36067.76404380798ms\n",
      "2709\n",
      "\n",
      "\n",
      "batch 43/848 loss: 0.8084417581558228 accuracy: 0.734375 time: 39552.63113975525ms\n",
      "2772\n",
      "\n",
      "\n",
      "batch 44/848 loss: 0.9041665196418762 accuracy: 0.765625 time: 38308.69007110596ms\n",
      "2835\n",
      "\n",
      "\n",
      "batch 45/848 loss: 0.7746626138687134 accuracy: 0.78125 time: 36357.55705833435ms\n",
      "2898\n",
      "\n",
      "\n",
      "batch 46/848 loss: 0.5874826908111572 accuracy: 0.8125 time: 35709.11478996277ms\n",
      "2961\n",
      "\n",
      "\n",
      "batch 47/848 loss: 0.8244587779045105 accuracy: 0.78125 time: 37800.20093917847ms\n",
      "3024\n",
      "\n",
      "\n",
      "batch 48/848 loss: 0.6228103637695312 accuracy: 0.859375 time: 36710.07299423218ms\n",
      "3087\n",
      "\n",
      "\n",
      "batch 49/848 loss: 0.8103862404823303 accuracy: 0.6875 time: 36722.20015525818ms\n",
      "3150\n",
      "\n",
      "\n",
      "batch 50/848 loss: 0.9483816623687744 accuracy: 0.703125 time: 36226.98616981506ms\n",
      "3213\n",
      "\n",
      "\n",
      "batch 51/848 loss: 0.6572051048278809 accuracy: 0.84375 time: 39625.83613395691ms\n",
      "3276\n",
      "\n",
      "\n",
      "batch 52/848 loss: 0.6893954277038574 accuracy: 0.78125 time: 36872.58195877075ms\n",
      "3339\n",
      "\n",
      "\n",
      "batch 53/848 loss: 0.6897512674331665 accuracy: 0.8125 time: 37382.25603103638ms\n",
      "3402\n",
      "\n",
      "\n",
      "batch 54/848 loss: 0.6070231199264526 accuracy: 0.78125 time: 36379.80008125305ms\n",
      "3465\n",
      "\n",
      "\n",
      "batch 55/848 loss: 0.598619282245636 accuracy: 0.75 time: 36285.90989112854ms\n",
      "3528\n",
      "\n",
      "\n",
      "batch 56/848 loss: 0.748041033744812 accuracy: 0.78125 time: 36831.65192604065ms\n",
      "3591\n",
      "\n",
      "\n",
      "batch 57/848 loss: 0.8590091466903687 accuracy: 0.734375 time: 38729.4659614563ms\n",
      "3654\n",
      "\n",
      "\n",
      "batch 58/848 loss: 0.7986114025115967 accuracy: 0.71875 time: 36853.68990898132ms\n",
      "3717\n",
      "\n",
      "\n",
      "batch 59/848 loss: 0.6442373394966125 accuracy: 0.796875 time: 37088.71817588806ms\n",
      "3780\n",
      "\n",
      "\n",
      "batch 60/848 loss: 0.7267770767211914 accuracy: 0.796875 time: 37936.96999549866ms\n",
      "3843\n",
      "\n",
      "\n",
      "batch 61/848 loss: 0.6915560960769653 accuracy: 0.796875 time: 35947.18790054321ms\n",
      "3906\n",
      "\n",
      "\n",
      "batch 62/848 loss: 0.9229665994644165 accuracy: 0.765625 time: 36114.665031433105ms\n",
      "3969\n",
      "\n",
      "\n",
      "batch 63/848 loss: 0.5204200148582458 accuracy: 0.8125 time: 36812.02983856201ms\n",
      "4032\n",
      "\n",
      "\n",
      "batch 63/848 loss: 0.8509694337844849 accuracy: 0.78125 time: 36899.994134902954ms\n",
      "4095\n",
      "\n",
      "\n",
      "batch 64/848 loss: 0.9638407826423645 accuracy: 0.6875 time: 37485.26310920715ms\n",
      "4158\n",
      "\n",
      "\n",
      "batch 65/848 loss: 1.248496651649475 accuracy: 0.609375 time: 36359.41004753113ms\n",
      "4221\n",
      "\n",
      "\n",
      "batch 66/848 loss: 0.9365793466567993 accuracy: 0.671875 time: 36347.02777862549ms\n",
      "4284\n",
      "\n",
      "\n",
      "batch 67/848 loss: 0.9066414833068848 accuracy: 0.765625 time: 36466.30120277405ms\n",
      "4347\n",
      "\n",
      "\n",
      "batch 68/848 loss: 0.3992435336112976 accuracy: 0.84375 time: 36502.463817596436ms\n",
      "4410\n",
      "\n",
      "\n",
      "batch 69/848 loss: 0.836124062538147 accuracy: 0.75 time: 36335.51788330078ms\n",
      "4473\n",
      "\n",
      "\n",
      "batch 70/848 loss: 0.6157103776931763 accuracy: 0.8125 time: 36210.41297912598ms\n",
      "4536\n",
      "\n",
      "\n",
      "batch 71/848 loss: 0.6515673398971558 accuracy: 0.828125 time: 40029.958963394165ms\n",
      "4599\n",
      "\n",
      "\n",
      "batch 72/848 loss: 0.8075194358825684 accuracy: 0.71875 time: 37391.562938690186ms\n",
      "4662\n",
      "\n",
      "\n",
      "batch 73/848 loss: 0.4936656951904297 accuracy: 0.828125 time: 36314.81313705444ms\n",
      "4725\n",
      "\n",
      "\n",
      "batch 74/848 loss: 0.8077806234359741 accuracy: 0.765625 time: 36296.36907577515ms\n",
      "4788\n",
      "\n",
      "\n",
      "batch 75/848 loss: 0.41399940848350525 accuracy: 0.859375 time: 36565.836906433105ms\n",
      "4851\n",
      "\n",
      "\n",
      "batch 76/848 loss: 0.763827919960022 accuracy: 0.75 time: 35680.54699897766ms\n",
      "4914\n",
      "\n",
      "\n",
      "batch 77/848 loss: 0.6038190126419067 accuracy: 0.78125 time: 35010.73694229126ms\n",
      "4977\n",
      "\n",
      "\n",
      "batch 78/848 loss: 0.7646967172622681 accuracy: 0.734375 time: 37191.230058670044ms\n",
      "5040\n",
      "\n",
      "\n",
      "batch 79/848 loss: 0.5295056700706482 accuracy: 0.84375 time: 35979.78687286377ms\n",
      "5103\n",
      "\n",
      "\n",
      "batch 80/848 loss: 0.5417234897613525 accuracy: 0.828125 time: 36791.64099693298ms\n",
      "5166\n",
      "\n",
      "\n",
      "batch 81/848 loss: 0.47413522005081177 accuracy: 0.875 time: 36424.65281486511ms\n",
      "5229\n",
      "\n",
      "\n",
      "batch 82/848 loss: 0.5374398231506348 accuracy: 0.84375 time: 35523.425817489624ms\n",
      "5292\n",
      "\n",
      "\n",
      "batch 83/848 loss: 0.6423571109771729 accuracy: 0.8125 time: 37609.0350151062ms\n",
      "5355\n",
      "\n",
      "\n",
      "batch 84/848 loss: 0.44730710983276367 accuracy: 0.84375 time: 40738.868951797485ms\n",
      "5418\n",
      "\n",
      "\n",
      "batch 85/848 loss: 0.9569016098976135 accuracy: 0.765625 time: 35842.62800216675ms\n",
      "5481\n",
      "\n",
      "\n",
      "batch 86/848 loss: 0.5932570695877075 accuracy: 0.8125 time: 36982.40804672241ms\n",
      "5544\n",
      "\n",
      "\n",
      "batch 87/848 loss: 0.5586329698562622 accuracy: 0.828125 time: 36919.69799995422ms\n",
      "5607\n",
      "\n",
      "\n",
      "batch 88/848 loss: 0.41501355171203613 accuracy: 0.859375 time: 36642.51804351807ms\n",
      "5670\n",
      "\n",
      "\n",
      "batch 89/848 loss: 0.6117477416992188 accuracy: 0.796875 time: 36943.912982940674ms\n",
      "5733\n",
      "\n",
      "\n",
      "batch 90/848 loss: 0.4130045175552368 accuracy: 0.890625 time: 36891.72101020813ms\n",
      "5796\n",
      "\n",
      "\n",
      "batch 91/848 loss: 0.5539603233337402 accuracy: 0.859375 time: 40201.06601715088ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5859\n",
      "\n",
      "\n",
      "batch 92/848 loss: 0.7157570123672485 accuracy: 0.75 time: 36616.47415161133ms\n",
      "5922\n",
      "\n",
      "\n",
      "batch 93/848 loss: 0.617450475692749 accuracy: 0.828125 time: 36788.80000114441ms\n",
      "5985\n",
      "\n",
      "\n",
      "batch 94/848 loss: 0.35400262475013733 accuracy: 0.875 time: 37137.56203651428ms\n",
      "6048\n",
      "\n",
      "\n",
      "batch 95/848 loss: 0.6113688945770264 accuracy: 0.78125 time: 36214.24317359924ms\n",
      "6111\n",
      "\n",
      "\n",
      "batch 96/848 loss: 0.5993003845214844 accuracy: 0.78125 time: 36211.43317222595ms\n",
      "6174\n",
      "\n",
      "\n",
      "batch 97/848 loss: 0.8923069834709167 accuracy: 0.734375 time: 36049.84998703003ms\n",
      "6237\n",
      "\n",
      "\n",
      "batch 98/848 loss: 0.6917034387588501 accuracy: 0.828125 time: 36641.39986038208ms\n",
      "6300\n",
      "\n",
      "\n",
      "batch 99/848 loss: 0.6299604773521423 accuracy: 0.796875 time: 37050.30417442322ms\n",
      "6363\n",
      "\n",
      "\n",
      "batch 100/848 loss: 0.4315394163131714 accuracy: 0.828125 time: 36281.221866607666ms\n",
      "6426\n",
      "\n",
      "\n",
      "batch 101/848 loss: 0.4805718660354614 accuracy: 0.859375 time: 35846.13299369812ms\n",
      "6489\n",
      "\n",
      "\n",
      "batch 102/848 loss: 0.5108283758163452 accuracy: 0.875 time: 36474.716901779175ms\n",
      "6552\n",
      "\n",
      "\n",
      "batch 103/848 loss: 0.42333123087882996 accuracy: 0.890625 time: 36093.68801116943ms\n",
      "6615\n",
      "\n",
      "\n",
      "batch 104/848 loss: 0.6102021336555481 accuracy: 0.8125 time: 36290.90905189514ms\n",
      "6678\n",
      "\n",
      "\n",
      "batch 105/848 loss: 0.40291428565979004 accuracy: 0.875 time: 37023.321866989136ms\n",
      "6741\n",
      "\n",
      "\n",
      "batch 106/848 loss: 0.4516809284687042 accuracy: 0.859375 time: 35353.53899002075ms\n",
      "6804\n",
      "\n",
      "\n",
      "batch 107/848 loss: 0.6156147718429565 accuracy: 0.8125 time: 37711.74216270447ms\n",
      "6867\n",
      "\n",
      "\n",
      "batch 108/848 loss: 0.3939287066459656 accuracy: 0.859375 time: 36951.663970947266ms\n",
      "6930\n",
      "\n",
      "\n",
      "batch 109/848 loss: 0.47652775049209595 accuracy: 0.828125 time: 37648.316860198975ms\n",
      "6993\n",
      "\n",
      "\n",
      "batch 110/848 loss: 0.7075899243354797 accuracy: 0.828125 time: 36818.121910095215ms\n",
      "7056\n",
      "\n",
      "\n",
      "batch 111/848 loss: 0.577965259552002 accuracy: 0.796875 time: 36439.77403640747ms\n",
      "7119\n",
      "\n",
      "\n",
      "batch 112/848 loss: 0.6293854713439941 accuracy: 0.828125 time: 36231.366872787476ms\n",
      "7182\n",
      "\n",
      "\n",
      "batch 113/848 loss: 0.4132459759712219 accuracy: 0.875 time: 36375.25010108948ms\n",
      "7245\n",
      "\n",
      "\n",
      "batch 114/848 loss: 0.7583903670310974 accuracy: 0.828125 time: 40749.017000198364ms\n",
      "7308\n",
      "\n",
      "\n",
      "batch 115/848 loss: 0.4465075433254242 accuracy: 0.875 time: 36356.60815238953ms\n",
      "7371\n",
      "\n",
      "\n",
      "batch 116/848 loss: 0.6730525493621826 accuracy: 0.8125 time: 36219.130992889404ms\n",
      "7434\n",
      "\n",
      "\n",
      "batch 117/848 loss: 0.7120466232299805 accuracy: 0.78125 time: 37610.60285568237ms\n",
      "7497\n",
      "\n",
      "\n",
      "batch 118/848 loss: 0.5042749643325806 accuracy: 0.84375 time: 36023.2949256897ms\n",
      "7560\n",
      "\n",
      "\n",
      "batch 119/848 loss: 0.41996562480926514 accuracy: 0.84375 time: 37369.66681480408ms\n",
      "7623\n",
      "\n",
      "\n",
      "batch 120/848 loss: 0.2871599793434143 accuracy: 0.90625 time: 35711.66801452637ms\n",
      "7686\n",
      "\n",
      "\n",
      "batch 121/848 loss: 0.5423610806465149 accuracy: 0.78125 time: 36104.642152786255ms\n",
      "7749\n",
      "\n",
      "\n",
      "batch 122/848 loss: 0.883518397808075 accuracy: 0.71875 time: 35598.79994392395ms\n",
      "7812\n",
      "\n",
      "\n",
      "batch 123/848 loss: 0.7597638368606567 accuracy: 0.765625 time: 37654.32810783386ms\n",
      "7875\n",
      "\n",
      "\n",
      "batch 124/848 loss: 1.2366642951965332 accuracy: 0.671875 time: 36959.22780036926ms\n",
      "7938\n",
      "\n",
      "\n",
      "batch 125/848 loss: 0.42426782846450806 accuracy: 0.84375 time: 35655.900955200195ms\n",
      "8001\n",
      "\n",
      "\n",
      "batch 126/848 loss: 0.5522190928459167 accuracy: 0.828125 time: 36334.24687385559ms\n",
      "8064\n",
      "\n",
      "\n",
      "batch 126/848 loss: 0.6906217932701111 accuracy: 0.78125 time: 37853.17587852478ms\n",
      "8127\n",
      "\n",
      "\n",
      "batch 127/848 loss: 0.4839740991592407 accuracy: 0.84375 time: 36566.320180892944ms\n",
      "8190\n",
      "\n",
      "\n",
      "batch 128/848 loss: 0.38306400179862976 accuracy: 0.890625 time: 35934.20720100403ms\n",
      "8253\n",
      "\n",
      "\n",
      "batch 129/848 loss: 0.3545345067977905 accuracy: 0.859375 time: 36100.750207901ms\n",
      "8316\n",
      "\n",
      "\n",
      "batch 130/848 loss: 0.4787009358406067 accuracy: 0.84375 time: 36935.546875ms\n",
      "8379\n",
      "\n",
      "\n",
      "batch 131/848 loss: 0.5245151519775391 accuracy: 0.890625 time: 37982.63597488403ms\n",
      "8442\n",
      "\n",
      "\n",
      "batch 132/848 loss: 0.4115232527256012 accuracy: 0.890625 time: 37244.361877441406ms\n",
      "8505\n",
      "\n",
      "\n",
      "batch 133/848 loss: 0.6688929796218872 accuracy: 0.71875 time: 36066.35403633118ms\n",
      "8568\n",
      "\n",
      "\n",
      "batch 134/848 loss: 0.557148814201355 accuracy: 0.84375 time: 34923.71106147766ms\n",
      "8631\n",
      "\n",
      "\n",
      "batch 135/848 loss: 0.6134412288665771 accuracy: 0.8125 time: 36335.45398712158ms\n",
      "8694\n",
      "\n",
      "\n",
      "batch 136/848 loss: 0.8153806924819946 accuracy: 0.75 time: 36883.960008621216ms\n",
      "8757\n",
      "\n",
      "\n",
      "batch 137/848 loss: 0.5763585567474365 accuracy: 0.84375 time: 35415.04406929016ms\n",
      "8820\n",
      "\n",
      "\n",
      "batch 138/848 loss: 0.32044804096221924 accuracy: 0.921875 time: 35518.5010433197ms\n",
      "8883\n",
      "\n",
      "\n",
      "batch 139/848 loss: 0.43662121891975403 accuracy: 0.828125 time: 37936.13004684448ms\n",
      "8946\n",
      "\n",
      "\n",
      "batch 140/848 loss: 0.6405698657035828 accuracy: 0.8125 time: 37592.195987701416ms\n",
      "9009\n",
      "\n",
      "\n",
      "batch 141/848 loss: 0.32893168926239014 accuracy: 0.90625 time: 35879.34899330139ms\n",
      "9072\n",
      "\n",
      "\n",
      "batch 142/848 loss: 0.6677765846252441 accuracy: 0.859375 time: 35697.87406921387ms\n",
      "9135\n",
      "\n",
      "\n",
      "batch 143/848 loss: 0.47599321603775024 accuracy: 0.84375 time: 37634.70101356506ms\n",
      "9198\n",
      "\n",
      "\n",
      "batch 144/848 loss: 0.25646862387657166 accuracy: 0.890625 time: 35987.658977508545ms\n",
      "9261\n",
      "\n",
      "\n",
      "batch 145/848 loss: 0.31003350019454956 accuracy: 0.921875 time: 36790.143966674805ms\n",
      "9324\n",
      "\n",
      "\n",
      "batch 146/848 loss: 0.34271836280822754 accuracy: 0.859375 time: 36359.92097854614ms\n",
      "9387\n",
      "\n",
      "\n",
      "batch 147/848 loss: 0.30543288588523865 accuracy: 0.921875 time: 36139.64295387268ms\n",
      "9450\n",
      "\n",
      "\n",
      "batch 148/848 loss: 0.31329065561294556 accuracy: 0.875 time: 37789.12091255188ms\n",
      "9513\n",
      "\n",
      "\n",
      "batch 149/848 loss: 0.5853486061096191 accuracy: 0.8125 time: 37796.51713371277ms\n",
      "9576\n",
      "\n",
      "\n",
      "batch 150/848 loss: 0.48269644379615784 accuracy: 0.8125 time: 35662.82510757446ms\n",
      "9639\n",
      "\n",
      "\n",
      "batch 151/848 loss: 0.5144124031066895 accuracy: 0.84375 time: 37160.244941711426ms\n",
      "9702\n",
      "\n",
      "\n",
      "batch 152/848 loss: 0.7781232595443726 accuracy: 0.78125 time: 36725.54087638855ms\n",
      "9765\n",
      "\n",
      "\n",
      "batch 153/848 loss: 0.42112112045288086 accuracy: 0.875 time: 36542.90199279785ms\n",
      "9828\n",
      "\n",
      "\n",
      "batch 154/848 loss: 0.400298148393631 accuracy: 0.875 time: 38225.97002983093ms\n",
      "9891\n",
      "\n",
      "\n",
      "batch 155/848 loss: 0.6299712657928467 accuracy: 0.796875 time: 36752.38013267517ms\n",
      "9954\n",
      "\n",
      "\n",
      "batch 156/848 loss: 0.39963987469673157 accuracy: 0.859375 time: 35757.22002983093ms\n",
      "10017\n",
      "\n",
      "\n",
      "batch 157/848 loss: 0.4707944393157959 accuracy: 0.875 time: 35818.17698478699ms\n",
      "10080\n",
      "\n",
      "\n",
      "batch 158/848 loss: 0.6065812110900879 accuracy: 0.796875 time: 36444.04196739197ms\n",
      "10143\n",
      "\n",
      "\n",
      "batch 159/848 loss: 0.5076999068260193 accuracy: 0.859375 time: 35957.13996887207ms\n",
      "10206\n",
      "\n",
      "\n",
      "batch 160/848 loss: 0.6503738760948181 accuracy: 0.8125 time: 35530.77411651611ms\n",
      "10269\n",
      "\n",
      "\n",
      "batch 161/848 loss: 0.3623519837856293 accuracy: 0.90625 time: 38865.00406265259ms\n",
      "10332\n",
      "\n",
      "\n",
      "batch 162/848 loss: 0.641949474811554 accuracy: 0.734375 time: 39101.688861846924ms\n",
      "10395\n",
      "\n",
      "\n",
      "batch 163/848 loss: 0.7133223414421082 accuracy: 0.78125 time: 36710.322856903076ms\n",
      "10458\n",
      "\n",
      "\n",
      "batch 164/848 loss: 0.2843078374862671 accuracy: 0.890625 time: 36412.320137023926ms\n",
      "10521\n",
      "\n",
      "\n",
      "batch 165/848 loss: 0.39426499605178833 accuracy: 0.84375 time: 35943.50981712341ms\n",
      "10584\n",
      "\n",
      "\n",
      "batch 166/848 loss: 0.41154325008392334 accuracy: 0.859375 time: 37720.20506858826ms\n",
      "10647\n",
      "\n",
      "\n",
      "batch 167/848 loss: 0.39501821994781494 accuracy: 0.859375 time: 37088.451862335205ms\n",
      "10710\n",
      "\n",
      "\n",
      "batch 168/848 loss: 0.5448618531227112 accuracy: 0.8125 time: 37019.026041030884ms\n",
      "10773\n",
      "\n",
      "\n",
      "batch 169/848 loss: 0.2816200852394104 accuracy: 0.9375 time: 38926.75805091858ms\n",
      "10836\n",
      "\n",
      "\n",
      "batch 170/848 loss: 0.4308744966983795 accuracy: 0.90625 time: 35908.10990333557ms\n",
      "10899\n",
      "\n",
      "\n",
      "batch 171/848 loss: 0.5880956649780273 accuracy: 0.828125 time: 37103.3239364624ms\n",
      "10962\n",
      "\n",
      "\n",
      "batch 172/848 loss: 0.28237080574035645 accuracy: 0.890625 time: 35605.560064315796ms\n",
      "11025\n",
      "\n",
      "\n",
      "batch 173/848 loss: 0.5919291377067566 accuracy: 0.765625 time: 36292.76394844055ms\n",
      "11088\n",
      "\n",
      "\n",
      "batch 174/848 loss: 0.5502146482467651 accuracy: 0.84375 time: 34646.419048309326ms\n",
      "11151\n",
      "\n",
      "\n",
      "batch 175/848 loss: 0.8019047975540161 accuracy: 0.734375 time: 37163.58304023743ms\n",
      "11214\n",
      "\n",
      "\n",
      "batch 176/848 loss: 0.5055367946624756 accuracy: 0.828125 time: 36712.43500709534ms\n",
      "11277\n",
      "\n",
      "\n",
      "batch 177/848 loss: 0.3598155975341797 accuracy: 0.875 time: 37025.59590339661ms\n",
      "11340\n",
      "\n",
      "\n",
      "batch 178/848 loss: 0.4655371904373169 accuracy: 0.875 time: 41277.28986740112ms\n",
      "11403\n",
      "\n",
      "\n",
      "batch 179/848 loss: 0.46487295627593994 accuracy: 0.859375 time: 36370.17798423767ms\n",
      "11466\n",
      "\n",
      "\n",
      "batch 180/848 loss: 0.601516842842102 accuracy: 0.796875 time: 36619.74596977234ms\n",
      "11529\n",
      "\n",
      "\n",
      "batch 181/848 loss: 0.3543431758880615 accuracy: 0.84375 time: 35961.27390861511ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11592\n",
      "\n",
      "\n",
      "batch 182/848 loss: 0.5003478527069092 accuracy: 0.859375 time: 35663.04111480713ms\n",
      "11655\n",
      "\n",
      "\n",
      "batch 183/848 loss: 0.600085437297821 accuracy: 0.8125 time: 36119.55189704895ms\n",
      "11718\n",
      "\n",
      "\n",
      "batch 184/848 loss: 0.37541526556015015 accuracy: 0.875 time: 35865.02194404602ms\n",
      "11781\n",
      "\n",
      "\n",
      "batch 185/848 loss: 0.42190513014793396 accuracy: 0.859375 time: 38316.04313850403ms\n",
      "11844\n",
      "\n",
      "\n",
      "batch 186/848 loss: 0.4126272201538086 accuracy: 0.875 time: 36707.53502845764ms\n",
      "11907\n",
      "\n",
      "\n",
      "batch 187/848 loss: 0.6077223420143127 accuracy: 0.828125 time: 36306.63585662842ms\n",
      "11970\n",
      "\n",
      "\n",
      "batch 188/848 loss: 0.523193359375 accuracy: 0.84375 time: 37297.849893569946ms\n",
      "12033\n",
      "\n",
      "\n",
      "batch 189/848 loss: 0.6465083360671997 accuracy: 0.796875 time: 36493.71790885925ms\n",
      "12096\n",
      "\n",
      "\n",
      "batch 189/848 loss: 0.47099465131759644 accuracy: 0.859375 time: 35940.72389602661ms\n",
      "12159\n",
      "\n",
      "\n",
      "batch 190/848 loss: 0.3683512508869171 accuracy: 0.875 time: 36708.43291282654ms\n",
      "12222\n",
      "\n",
      "\n",
      "batch 191/848 loss: 0.4958621859550476 accuracy: 0.859375 time: 36924.23486709595ms\n",
      "12285\n",
      "\n",
      "\n",
      "batch 192/848 loss: 0.6705597639083862 accuracy: 0.828125 time: 36694.790840148926ms\n",
      "12348\n",
      "\n",
      "\n",
      "batch 193/848 loss: 0.39932093024253845 accuracy: 0.84375 time: 36494.1041469574ms\n",
      "12411\n",
      "\n",
      "\n",
      "batch 194/848 loss: 0.4106265902519226 accuracy: 0.875 time: 36665.6608581543ms\n",
      "12474\n",
      "\n",
      "\n",
      "batch 195/848 loss: 0.45128774642944336 accuracy: 0.875 time: 36791.11289978027ms\n",
      "12537\n",
      "\n",
      "\n",
      "batch 196/848 loss: 0.4250667691230774 accuracy: 0.875 time: 37180.981159210205ms\n",
      "12600\n",
      "\n",
      "\n",
      "batch 197/848 loss: 0.1872568428516388 accuracy: 0.921875 time: 35910.12096405029ms\n",
      "12663\n",
      "\n",
      "\n",
      "batch 198/848 loss: 0.39924314618110657 accuracy: 0.875 time: 36896.7170715332ms\n",
      "12726\n",
      "\n",
      "\n",
      "batch 199/848 loss: 0.4519578516483307 accuracy: 0.828125 time: 36864.028215408325ms\n",
      "12789\n",
      "\n",
      "\n",
      "batch 200/848 loss: 0.5687941312789917 accuracy: 0.8125 time: 37587.10694313049ms\n",
      "12852\n",
      "\n",
      "\n",
      "batch 201/848 loss: 0.49863189458847046 accuracy: 0.84375 time: 37638.85402679443ms\n",
      "12915\n",
      "\n",
      "\n",
      "batch 202/848 loss: 0.29325371980667114 accuracy: 0.90625 time: 36689.931869506836ms\n",
      "12978\n",
      "\n",
      "\n",
      "batch 203/848 loss: 0.6747018694877625 accuracy: 0.875 time: 37572.10898399353ms\n",
      "13041\n",
      "\n",
      "\n",
      "batch 204/848 loss: 0.3751882314682007 accuracy: 0.890625 time: 36066.442012786865ms\n",
      "13104\n",
      "\n",
      "\n",
      "batch 205/848 loss: 0.39523008465766907 accuracy: 0.921875 time: 35909.76595878601ms\n",
      "13167\n",
      "\n",
      "\n",
      "batch 206/848 loss: 0.31508946418762207 accuracy: 0.890625 time: 36991.76502227783ms\n",
      "13230\n",
      "\n",
      "\n",
      "batch 207/848 loss: 0.5582305192947388 accuracy: 0.84375 time: 35758.85105133057ms\n",
      "13293\n",
      "\n",
      "\n",
      "batch 208/848 loss: 0.9206759929656982 accuracy: 0.71875 time: 35929.157972335815ms\n",
      "13356\n",
      "\n",
      "\n",
      "batch 209/848 loss: 0.4269680380821228 accuracy: 0.859375 time: 36020.941972732544ms\n",
      "13419\n",
      "\n",
      "\n",
      "batch 210/848 loss: 0.32279813289642334 accuracy: 0.875 time: 37543.58100891113ms\n",
      "13482\n",
      "\n",
      "\n",
      "batch 211/848 loss: 0.27353382110595703 accuracy: 0.890625 time: 35917.07110404968ms\n",
      "13545\n",
      "\n",
      "\n",
      "batch 212/848 loss: 0.29861336946487427 accuracy: 0.90625 time: 35569.97799873352ms\n",
      "13608\n",
      "\n",
      "\n",
      "batch 213/848 loss: 0.22118866443634033 accuracy: 0.9375 time: 36481.00686073303ms\n",
      "13671\n",
      "\n",
      "\n",
      "batch 214/848 loss: 0.33747267723083496 accuracy: 0.859375 time: 37735.39686203003ms\n",
      "13734\n",
      "\n",
      "\n",
      "batch 215/848 loss: 0.7674741744995117 accuracy: 0.84375 time: 36134.23204421997ms\n",
      "13797\n",
      "\n",
      "\n",
      "batch 216/848 loss: 0.19378140568733215 accuracy: 0.921875 time: 37166.682958602905ms\n",
      "13860\n",
      "\n",
      "\n",
      "batch 217/848 loss: 0.35633203387260437 accuracy: 0.921875 time: 35546.0569858551ms\n",
      "13923\n",
      "\n",
      "\n",
      "batch 218/848 loss: 0.5294811129570007 accuracy: 0.859375 time: 35919.090032577515ms\n",
      "13986\n",
      "\n",
      "\n",
      "batch 219/848 loss: 0.5850808620452881 accuracy: 0.828125 time: 36008.48889350891ms\n",
      "14049\n",
      "\n",
      "\n",
      "batch 220/848 loss: 0.5701380968093872 accuracy: 0.796875 time: 39178.51996421814ms\n",
      "14112\n",
      "\n",
      "\n",
      "batch 221/848 loss: 0.2542610168457031 accuracy: 0.90625 time: 35956.99906349182ms\n",
      "14175\n",
      "\n",
      "\n",
      "batch 222/848 loss: 0.5351418256759644 accuracy: 0.859375 time: 36111.29903793335ms\n",
      "14238\n",
      "\n",
      "\n",
      "batch 223/848 loss: 0.22499153017997742 accuracy: 0.90625 time: 37313.8952255249ms\n",
      "14301\n",
      "\n",
      "\n",
      "batch 224/848 loss: 0.14202478528022766 accuracy: 0.96875 time: 37129.759073257446ms\n",
      "14364\n",
      "\n",
      "\n",
      "batch 225/848 loss: 0.3452969789505005 accuracy: 0.890625 time: 36970.19815444946ms\n",
      "14427\n",
      "\n",
      "\n",
      "batch 226/848 loss: 0.21145862340927124 accuracy: 0.9375 time: 36220.526933670044ms\n",
      "14490\n",
      "\n",
      "\n",
      "batch 227/848 loss: 0.48562753200531006 accuracy: 0.828125 time: 36870.56016921997ms\n",
      "14553\n",
      "\n",
      "\n",
      "batch 228/848 loss: 0.4383389353752136 accuracy: 0.8125 time: 36510.70594787598ms\n",
      "14616\n",
      "\n",
      "\n",
      "batch 229/848 loss: 0.7110333442687988 accuracy: 0.765625 time: 37174.49498176575ms\n",
      "14679\n",
      "\n",
      "\n",
      "batch 230/848 loss: 0.8296681046485901 accuracy: 0.75 time: 36734.12299156189ms\n",
      "14742\n",
      "\n",
      "\n",
      "batch 231/848 loss: 0.4846186637878418 accuracy: 0.859375 time: 36431.293964385986ms\n",
      "14805\n",
      "\n",
      "\n",
      "batch 232/848 loss: 0.2742635905742645 accuracy: 0.9375 time: 36434.39483642578ms\n",
      "14868\n",
      "\n",
      "\n",
      "batch 233/848 loss: 0.20898684859275818 accuracy: 0.90625 time: 36113.56997489929ms\n",
      "14931\n",
      "\n",
      "\n",
      "batch 234/848 loss: 0.38825008273124695 accuracy: 0.8125 time: 35719.621896743774ms\n",
      "14994\n",
      "\n",
      "\n",
      "batch 235/848 loss: 0.3332516849040985 accuracy: 0.890625 time: 38662.61887550354ms\n",
      "15057\n",
      "\n",
      "\n",
      "batch 236/848 loss: 0.4213460087776184 accuracy: 0.890625 time: 38662.266969680786ms\n",
      "15120\n",
      "\n",
      "\n",
      "batch 237/848 loss: 0.5915237665176392 accuracy: 0.828125 time: 36464.23697471619ms\n",
      "15183\n",
      "\n",
      "\n",
      "batch 238/848 loss: 0.41200560331344604 accuracy: 0.890625 time: 35402.390003204346ms\n",
      "15246\n",
      "\n",
      "\n",
      "batch 239/848 loss: 0.3705257773399353 accuracy: 0.859375 time: 36110.59093475342ms\n",
      "15309\n",
      "\n",
      "\n",
      "batch 240/848 loss: 0.2681792974472046 accuracy: 0.875 time: 36465.80505371094ms\n",
      "15372\n",
      "\n",
      "\n",
      "batch 241/848 loss: 0.2589268088340759 accuracy: 0.90625 time: 36377.5749206543ms\n",
      "15435\n",
      "\n",
      "\n",
      "batch 242/848 loss: 0.32019519805908203 accuracy: 0.9375 time: 36440.20318984985ms\n",
      "15498\n",
      "\n",
      "\n",
      "batch 243/848 loss: 0.27280211448669434 accuracy: 0.890625 time: 35846.57907485962ms\n",
      "15561\n",
      "\n",
      "\n",
      "batch 244/848 loss: 0.3719654083251953 accuracy: 0.90625 time: 35705.97195625305ms\n",
      "15624\n",
      "\n",
      "\n",
      "batch 245/848 loss: 0.5738264322280884 accuracy: 0.8125 time: 36607.555866241455ms\n",
      "15687\n",
      "\n",
      "\n",
      "batch 246/848 loss: 0.2624810039997101 accuracy: 0.9375 time: 37601.46188735962ms\n",
      "15750\n",
      "\n",
      "\n",
      "batch 247/848 loss: 0.32442885637283325 accuracy: 0.890625 time: 35871.88911437988ms\n",
      "15813\n",
      "\n",
      "\n",
      "batch 248/848 loss: 0.42701485753059387 accuracy: 0.828125 time: 37255.780935287476ms\n",
      "15876\n",
      "\n",
      "\n",
      "batch 249/848 loss: 0.2709655463695526 accuracy: 0.9375 time: 36279.19816970825ms\n",
      "15939\n",
      "\n",
      "\n",
      "batch 250/848 loss: 0.5342345833778381 accuracy: 0.8125 time: 36781.574010849ms\n",
      "16002\n",
      "\n",
      "\n",
      "batch 251/848 loss: 0.7070671319961548 accuracy: 0.796875 time: 38215.490102767944ms\n",
      "16065\n",
      "\n",
      "\n",
      "batch 252/848 loss: 0.2426358312368393 accuracy: 0.90625 time: 36569.99111175537ms\n",
      "16128\n",
      "\n",
      "\n",
      "batch 252/848 loss: 0.3095945119857788 accuracy: 0.90625 time: 36620.408058166504ms\n",
      "16191\n",
      "\n",
      "\n",
      "batch 253/848 loss: 0.124402716755867 accuracy: 0.984375 time: 36648.30493927002ms\n",
      "16254\n",
      "\n",
      "\n",
      "batch 254/848 loss: 0.3020251393318176 accuracy: 0.890625 time: 36544.50297355652ms\n",
      "16317\n",
      "\n",
      "\n",
      "batch 255/848 loss: 0.3602270483970642 accuracy: 0.890625 time: 35480.05986213684ms\n",
      "16380\n",
      "\n",
      "\n",
      "batch 256/848 loss: 0.4564262628555298 accuracy: 0.875 time: 36538.04302215576ms\n",
      "16443\n",
      "\n",
      "\n",
      "batch 257/848 loss: 0.2624749541282654 accuracy: 0.90625 time: 36882.72023200989ms\n",
      "16506\n",
      "\n",
      "\n",
      "batch 258/848 loss: 0.31784892082214355 accuracy: 0.859375 time: 38271.96788787842ms\n",
      "16569\n",
      "\n",
      "\n",
      "batch 259/848 loss: 0.4257766604423523 accuracy: 0.875 time: 36318.10903549194ms\n",
      "16632\n",
      "\n",
      "\n",
      "batch 260/848 loss: 0.24790224432945251 accuracy: 0.9375 time: 36809.43202972412ms\n",
      "16695\n",
      "\n",
      "\n",
      "batch 261/848 loss: 0.297756552696228 accuracy: 0.90625 time: 35488.73996734619ms\n",
      "16758\n",
      "\n",
      "\n",
      "batch 262/848 loss: 0.3895459771156311 accuracy: 0.859375 time: 36449.63192939758ms\n",
      "16821\n",
      "\n",
      "\n",
      "batch 263/848 loss: 0.44563987851142883 accuracy: 0.859375 time: 36088.28783035278ms\n",
      "16884\n",
      "\n",
      "\n",
      "batch 264/848 loss: 0.3730175793170929 accuracy: 0.875 time: 37053.6949634552ms\n",
      "16947\n",
      "\n",
      "\n",
      "batch 265/848 loss: 0.3635646104812622 accuracy: 0.890625 time: 36059.77511405945ms\n",
      "17010\n",
      "\n",
      "\n",
      "batch 266/848 loss: 0.5289862155914307 accuracy: 0.84375 time: 37218.43886375427ms\n",
      "17073\n",
      "\n",
      "\n",
      "batch 267/848 loss: 0.3257588744163513 accuracy: 0.84375 time: 36438.018798828125ms\n",
      "17136\n",
      "\n",
      "\n",
      "batch 268/848 loss: 0.5800151824951172 accuracy: 0.796875 time: 37126.55019760132ms\n",
      "17199\n",
      "\n",
      "\n",
      "batch 269/848 loss: 0.2538747787475586 accuracy: 0.953125 time: 36050.196170806885ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17262\n",
      "\n",
      "\n",
      "batch 270/848 loss: 0.38841789960861206 accuracy: 0.890625 time: 35989.23587799072ms\n",
      "17325\n",
      "\n",
      "\n",
      "batch 271/848 loss: 0.2598201036453247 accuracy: 0.921875 time: 36835.996866226196ms\n",
      "17388\n",
      "\n",
      "\n",
      "batch 272/848 loss: 0.6807568073272705 accuracy: 0.796875 time: 36088.54103088379ms\n",
      "17451\n",
      "\n",
      "\n",
      "batch 273/848 loss: 0.18042686581611633 accuracy: 0.9375 time: 36050.66013336182ms\n",
      "17514\n",
      "\n",
      "\n",
      "batch 274/848 loss: 0.37025758624076843 accuracy: 0.921875 time: 36412.42694854736ms\n",
      "17577\n",
      "\n",
      "\n",
      "batch 275/848 loss: 0.3459434509277344 accuracy: 0.875 time: 37436.46001815796ms\n",
      "17640\n",
      "\n",
      "\n",
      "batch 276/848 loss: 0.243789404630661 accuracy: 0.90625 time: 37274.94478225708ms\n",
      "17703\n",
      "\n",
      "\n",
      "batch 277/848 loss: 0.35301658511161804 accuracy: 0.890625 time: 36901.44395828247ms\n",
      "17766\n",
      "\n",
      "\n",
      "batch 278/848 loss: 0.45320865511894226 accuracy: 0.875 time: 36550.62985420227ms\n",
      "17829\n",
      "\n",
      "\n",
      "batch 279/848 loss: 0.3525760769844055 accuracy: 0.921875 time: 38148.836851119995ms\n",
      "17892\n",
      "\n",
      "\n",
      "batch 280/848 loss: 0.13213923573493958 accuracy: 0.96875 time: 36835.66999435425ms\n",
      "17955\n",
      "\n",
      "\n",
      "batch 281/848 loss: 0.35004812479019165 accuracy: 0.90625 time: 38187.73078918457ms\n",
      "18018\n",
      "\n",
      "\n",
      "batch 282/848 loss: 0.2473207414150238 accuracy: 0.90625 time: 36633.62908363342ms\n",
      "18081\n",
      "\n",
      "\n",
      "batch 283/848 loss: 0.2032027393579483 accuracy: 0.9375 time: 35725.29697418213ms\n",
      "18144\n",
      "\n",
      "\n",
      "batch 284/848 loss: 0.07962751388549805 accuracy: 0.96875 time: 36201.725006103516ms\n",
      "18207\n",
      "\n",
      "\n",
      "batch 285/848 loss: 0.45536017417907715 accuracy: 0.859375 time: 35862.683057785034ms\n",
      "18270\n",
      "\n",
      "\n",
      "batch 286/848 loss: 0.2641686201095581 accuracy: 0.921875 time: 35490.878105163574ms\n",
      "18333\n",
      "\n",
      "\n",
      "batch 287/848 loss: 0.3314761519432068 accuracy: 0.90625 time: 35385.14804840088ms\n",
      "18396\n",
      "\n",
      "\n",
      "batch 288/848 loss: 0.41076773405075073 accuracy: 0.875 time: 36456.583976745605ms\n",
      "18459\n",
      "\n",
      "\n",
      "batch 289/848 loss: 0.589551568031311 accuracy: 0.8125 time: 35835.201025009155ms\n",
      "18522\n",
      "\n",
      "\n",
      "batch 290/848 loss: 0.4345141649246216 accuracy: 0.90625 time: 35948.24814796448ms\n",
      "18585\n",
      "\n",
      "\n",
      "batch 291/848 loss: 0.3128684461116791 accuracy: 0.921875 time: 38432.3570728302ms\n",
      "18648\n",
      "\n",
      "\n",
      "batch 292/848 loss: 0.4872450828552246 accuracy: 0.828125 time: 35695.396900177ms\n",
      "18711\n",
      "\n",
      "\n",
      "batch 293/848 loss: 0.27726486325263977 accuracy: 0.890625 time: 35526.8440246582ms\n",
      "18774\n",
      "\n",
      "\n",
      "batch 294/848 loss: 0.3019941747188568 accuracy: 0.90625 time: 36396.67201042175ms\n",
      "18837\n",
      "\n",
      "\n",
      "batch 295/848 loss: 0.37069207429885864 accuracy: 0.890625 time: 35713.911056518555ms\n",
      "18900\n",
      "\n",
      "\n",
      "batch 296/848 loss: 0.3339204788208008 accuracy: 0.859375 time: 35642.059087753296ms\n",
      "18963\n",
      "\n",
      "\n",
      "batch 297/848 loss: 0.33590155839920044 accuracy: 0.875 time: 36938.38095664978ms\n",
      "19026\n",
      "\n",
      "\n",
      "batch 298/848 loss: 0.2510259747505188 accuracy: 0.90625 time: 35678.04408073425ms\n",
      "19089\n",
      "\n",
      "\n",
      "batch 299/848 loss: 0.48300397396087646 accuracy: 0.875 time: 37936.826944351196ms\n",
      "19152\n",
      "\n",
      "\n",
      "batch 300/848 loss: 0.3599299490451813 accuracy: 0.921875 time: 36850.619077682495ms\n",
      "19215\n",
      "\n",
      "\n",
      "batch 301/848 loss: 0.5963587760925293 accuracy: 0.796875 time: 37671.602964401245ms\n",
      "19278\n",
      "\n",
      "\n",
      "batch 302/848 loss: 0.5527364015579224 accuracy: 0.84375 time: 36311.269998550415ms\n",
      "19341\n",
      "\n",
      "\n",
      "batch 303/848 loss: 0.5084972381591797 accuracy: 0.828125 time: 35604.62999343872ms\n",
      "19404\n",
      "\n",
      "\n",
      "batch 304/848 loss: 0.3777935206890106 accuracy: 0.875 time: 38905.065059661865ms\n",
      "19467\n",
      "\n",
      "\n",
      "batch 305/848 loss: 0.6929565072059631 accuracy: 0.84375 time: 36106.292963027954ms\n",
      "19530\n",
      "\n",
      "\n",
      "batch 306/848 loss: 0.43571576476097107 accuracy: 0.84375 time: 36017.70496368408ms\n",
      "19593\n",
      "\n",
      "\n",
      "batch 307/848 loss: 0.5126360654830933 accuracy: 0.859375 time: 35887.63093948364ms\n",
      "19656\n",
      "\n",
      "\n",
      "batch 308/848 loss: 0.547283411026001 accuracy: 0.859375 time: 35519.11497116089ms\n",
      "19719\n",
      "\n",
      "\n",
      "batch 309/848 loss: 0.5031078457832336 accuracy: 0.84375 time: 35998.08883666992ms\n",
      "19782\n",
      "\n",
      "\n",
      "batch 310/848 loss: 0.3676905333995819 accuracy: 0.875 time: 36046.90718650818ms\n",
      "19845\n",
      "\n",
      "\n",
      "batch 311/848 loss: 0.16384872794151306 accuracy: 0.953125 time: 35360.67509651184ms\n",
      "19908\n",
      "\n",
      "\n",
      "batch 312/848 loss: 0.267155259847641 accuracy: 0.921875 time: 36455.85608482361ms\n",
      "19971\n",
      "\n",
      "\n",
      "batch 313/848 loss: 0.2190297245979309 accuracy: 0.953125 time: 36210.784912109375ms\n",
      "20034\n",
      "\n",
      "\n",
      "batch 314/848 loss: 0.2686092257499695 accuracy: 0.90625 time: 37123.05998802185ms\n",
      "20097\n",
      "\n",
      "\n",
      "batch 315/848 loss: 0.512294590473175 accuracy: 0.796875 time: 35954.85281944275ms\n",
      "20160\n",
      "\n",
      "\n",
      "batch 315/848 loss: 0.5841027498245239 accuracy: 0.859375 time: 38092.25392341614ms\n",
      "20223\n",
      "\n",
      "\n",
      "batch 316/848 loss: 0.29215556383132935 accuracy: 0.90625 time: 36683.42089653015ms\n",
      "20286\n",
      "\n",
      "\n",
      "batch 317/848 loss: 0.14017531275749207 accuracy: 0.953125 time: 36800.92906951904ms\n",
      "20349\n",
      "\n",
      "\n",
      "batch 318/848 loss: 0.21283189952373505 accuracy: 0.921875 time: 36976.5841960907ms\n",
      "20412\n",
      "\n",
      "\n",
      "batch 319/848 loss: 0.1550561487674713 accuracy: 0.9375 time: 35716.79711341858ms\n",
      "20475\n",
      "\n",
      "\n",
      "batch 320/848 loss: 0.5558748245239258 accuracy: 0.828125 time: 35709.177017211914ms\n",
      "20538\n",
      "\n",
      "\n",
      "batch 321/848 loss: 0.15645013749599457 accuracy: 0.9375 time: 36043.70617866516ms\n",
      "20601\n",
      "\n",
      "\n",
      "batch 322/848 loss: 0.3095420300960541 accuracy: 0.890625 time: 36340.19494056702ms\n",
      "20664\n",
      "\n",
      "\n",
      "batch 323/848 loss: 0.20916816592216492 accuracy: 0.953125 time: 37825.09112358093ms\n",
      "20727\n",
      "\n",
      "\n",
      "batch 324/848 loss: 0.3714146018028259 accuracy: 0.84375 time: 36313.38715553284ms\n",
      "20790\n",
      "\n",
      "\n",
      "batch 325/848 loss: 0.4324924051761627 accuracy: 0.875 time: 34838.82999420166ms\n",
      "20853\n",
      "\n",
      "\n",
      "batch 326/848 loss: 0.3142485022544861 accuracy: 0.859375 time: 35959.726095199585ms\n",
      "20916\n",
      "\n",
      "\n",
      "batch 327/848 loss: 0.3050902485847473 accuracy: 0.875 time: 37084.49101448059ms\n",
      "20979\n",
      "\n",
      "\n",
      "batch 328/848 loss: 0.5280064344406128 accuracy: 0.875 time: 35491.21594429016ms\n",
      "21042\n",
      "\n",
      "\n",
      "batch 329/848 loss: 0.23505361378192902 accuracy: 0.921875 time: 36379.392862319946ms\n",
      "21105\n",
      "\n",
      "\n",
      "batch 330/848 loss: 0.3909277319908142 accuracy: 0.859375 time: 37921.34714126587ms\n",
      "21168\n",
      "\n",
      "\n",
      "batch 331/848 loss: 0.205426886677742 accuracy: 0.9375 time: 36632.076025009155ms\n",
      "21231\n",
      "\n",
      "\n",
      "batch 332/848 loss: 0.3038172125816345 accuracy: 0.921875 time: 35878.46803665161ms\n",
      "21294\n",
      "\n",
      "\n",
      "batch 333/848 loss: 0.27514052391052246 accuracy: 0.875 time: 36147.850036621094ms\n",
      "21357\n",
      "\n",
      "\n",
      "batch 334/848 loss: 0.28603339195251465 accuracy: 0.90625 time: 36142.57597923279ms\n",
      "21420\n",
      "\n",
      "\n",
      "batch 335/848 loss: 0.5127341747283936 accuracy: 0.84375 time: 36911.73696517944ms\n",
      "21483\n",
      "\n",
      "\n",
      "batch 336/848 loss: 0.3851262629032135 accuracy: 0.90625 time: 37250.880002975464ms\n",
      "21546\n",
      "\n",
      "\n",
      "batch 337/848 loss: 0.18804486095905304 accuracy: 0.953125 time: 36015.64407348633ms\n",
      "21609\n",
      "\n",
      "\n",
      "batch 338/848 loss: 0.18397881090641022 accuracy: 0.9375 time: 37525.21085739136ms\n",
      "21672\n",
      "\n",
      "\n",
      "batch 339/848 loss: 0.48024508357048035 accuracy: 0.875 time: 36341.26091003418ms\n",
      "21735\n",
      "\n",
      "\n",
      "batch 340/848 loss: 0.4774923324584961 accuracy: 0.890625 time: 37309.897899627686ms\n",
      "21798\n",
      "\n",
      "\n",
      "batch 341/848 loss: 0.23269444704055786 accuracy: 0.9375 time: 37064.37611579895ms\n",
      "21861\n",
      "\n",
      "\n",
      "batch 342/848 loss: 0.4327695071697235 accuracy: 0.84375 time: 37508.4969997406ms\n",
      "21924\n",
      "\n",
      "\n",
      "batch 343/848 loss: 0.6266554594039917 accuracy: 0.8125 time: 36275.964975357056ms\n",
      "21987\n",
      "\n",
      "\n",
      "batch 344/848 loss: 0.4451451897621155 accuracy: 0.84375 time: 35983.41393470764ms\n",
      "22050\n",
      "\n",
      "\n",
      "batch 345/848 loss: 0.4283365309238434 accuracy: 0.875 time: 36712.85009384155ms\n",
      "22113\n",
      "\n",
      "\n",
      "batch 346/848 loss: 0.5578223466873169 accuracy: 0.8125 time: 38168.12491416931ms\n",
      "22176\n",
      "\n",
      "\n",
      "batch 347/848 loss: 0.2732924222946167 accuracy: 0.921875 time: 36300.23002624512ms\n",
      "22239\n",
      "\n",
      "\n",
      "batch 348/848 loss: 0.31688445806503296 accuracy: 0.875 time: 36270.90787887573ms\n",
      "22302\n",
      "\n",
      "\n",
      "batch 349/848 loss: 0.3358321785926819 accuracy: 0.890625 time: 36619.98987197876ms\n",
      "22365\n",
      "\n",
      "\n",
      "batch 350/848 loss: 0.3334326148033142 accuracy: 0.90625 time: 36164.91603851318ms\n",
      "22428\n",
      "\n",
      "\n",
      "batch 351/848 loss: 0.2779584527015686 accuracy: 0.921875 time: 36104.51817512512ms\n",
      "22491\n",
      "\n",
      "\n",
      "batch 352/848 loss: 0.30241939425468445 accuracy: 0.90625 time: 36633.74400138855ms\n",
      "22554\n",
      "\n",
      "\n",
      "batch 353/848 loss: 0.2605859041213989 accuracy: 0.921875 time: 37234.703063964844ms\n",
      "22617\n",
      "\n",
      "\n",
      "batch 354/848 loss: 0.4136970341205597 accuracy: 0.890625 time: 36385.00905036926ms\n",
      "22680\n",
      "\n",
      "\n",
      "batch 355/848 loss: 0.4378352165222168 accuracy: 0.921875 time: 36999.213218688965ms\n",
      "22743\n",
      "\n",
      "\n",
      "batch 356/848 loss: 0.6778304576873779 accuracy: 0.875 time: 35850.456953048706ms\n",
      "22806\n",
      "\n",
      "\n",
      "batch 357/848 loss: 0.3739467263221741 accuracy: 0.90625 time: 35954.64611053467ms\n",
      "22869\n",
      "\n",
      "\n",
      "batch 358/848 loss: 0.440717875957489 accuracy: 0.875 time: 42216.692209243774ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22932\n",
      "\n",
      "\n",
      "batch 359/848 loss: 0.3586117625236511 accuracy: 0.859375 time: 38013.88597488403ms\n",
      "22995\n",
      "\n",
      "\n",
      "batch 360/848 loss: 0.44684600830078125 accuracy: 0.890625 time: 40253.59582901001ms\n",
      "23058\n",
      "\n",
      "\n",
      "batch 361/848 loss: 0.20704299211502075 accuracy: 0.953125 time: 36701.94983482361ms\n",
      "23121\n",
      "\n",
      "\n",
      "batch 362/848 loss: 0.12817920744419098 accuracy: 0.984375 time: 38181.861877441406ms\n",
      "23184\n",
      "\n",
      "\n",
      "batch 363/848 loss: 0.217647522687912 accuracy: 0.9375 time: 36988.0530834198ms\n",
      "23247\n",
      "\n",
      "\n",
      "batch 364/848 loss: 0.38218796253204346 accuracy: 0.859375 time: 37852.83398628235ms\n",
      "23310\n",
      "\n",
      "\n",
      "batch 365/848 loss: 0.2670170068740845 accuracy: 0.875 time: 37765.27810096741ms\n",
      "23373\n",
      "\n",
      "\n",
      "batch 366/848 loss: 0.3840522766113281 accuracy: 0.859375 time: 37713.847160339355ms\n",
      "23436\n",
      "\n",
      "\n",
      "batch 367/848 loss: 0.1700577437877655 accuracy: 0.953125 time: 37105.39793968201ms\n",
      "23499\n",
      "\n",
      "\n",
      "batch 368/848 loss: 0.4404084086418152 accuracy: 0.828125 time: 37892.539978027344ms\n",
      "23562\n",
      "\n",
      "\n",
      "batch 369/848 loss: 0.36440902948379517 accuracy: 0.875 time: 36202.269077301025ms\n",
      "23625\n",
      "\n",
      "\n",
      "batch 370/848 loss: 0.2822246551513672 accuracy: 0.875 time: 38213.47618103027ms\n",
      "23688\n",
      "\n",
      "\n",
      "batch 371/848 loss: 0.42561912536621094 accuracy: 0.84375 time: 35913.16103935242ms\n",
      "23751\n",
      "\n",
      "\n",
      "batch 372/848 loss: 0.5189815163612366 accuracy: 0.875 time: 36966.36891365051ms\n",
      "23814\n",
      "\n",
      "\n",
      "batch 373/848 loss: 0.31787025928497314 accuracy: 0.921875 time: 37249.932050704956ms\n",
      "23877\n",
      "\n",
      "\n",
      "batch 374/848 loss: 0.21050328016281128 accuracy: 0.9375 time: 35759.624004364014ms\n",
      "23940\n",
      "\n",
      "\n",
      "batch 375/848 loss: 0.4353090226650238 accuracy: 0.875 time: 37309.92102622986ms\n",
      "24003\n",
      "\n",
      "\n",
      "batch 376/848 loss: 0.17233118414878845 accuracy: 0.9375 time: 36822.052001953125ms\n",
      "24066\n",
      "\n",
      "\n",
      "batch 377/848 loss: 0.15793970227241516 accuracy: 0.9375 time: 37119.922161102295ms\n",
      "24129\n",
      "\n",
      "\n",
      "batch 378/848 loss: 0.38193511962890625 accuracy: 0.84375 time: 39597.41401672363ms\n",
      "24192\n",
      "\n",
      "\n",
      "batch 378/848 loss: 0.38265708088874817 accuracy: 0.90625 time: 35716.47906303406ms\n",
      "24255\n",
      "\n",
      "\n",
      "batch 379/848 loss: 0.2634027600288391 accuracy: 0.90625 time: 37993.81518363953ms\n",
      "24318\n",
      "\n",
      "\n",
      "batch 380/848 loss: 0.48312366008758545 accuracy: 0.84375 time: 35985.14986038208ms\n",
      "24381\n",
      "\n",
      "\n",
      "batch 381/848 loss: 0.18264609575271606 accuracy: 0.921875 time: 37508.21495056152ms\n",
      "24444\n",
      "\n",
      "\n",
      "batch 382/848 loss: 0.3188369870185852 accuracy: 0.859375 time: 36805.69911003113ms\n",
      "24507\n",
      "\n",
      "\n",
      "batch 383/848 loss: 0.26013386249542236 accuracy: 0.890625 time: 36459.67984199524ms\n",
      "24570\n",
      "\n",
      "\n",
      "batch 384/848 loss: 0.18206492066383362 accuracy: 0.9375 time: 35754.99606132507ms\n",
      "24633\n",
      "\n",
      "\n",
      "batch 385/848 loss: 0.42699164152145386 accuracy: 0.890625 time: 35599.07793998718ms\n",
      "24696\n",
      "\n",
      "\n",
      "batch 386/848 loss: 0.3888261914253235 accuracy: 0.875 time: 35864.51292037964ms\n",
      "24759\n",
      "\n",
      "\n",
      "batch 387/848 loss: 0.5507143139839172 accuracy: 0.875 time: 37828.8140296936ms\n",
      "24822\n",
      "\n",
      "\n",
      "batch 388/848 loss: 0.3234778046607971 accuracy: 0.9375 time: 36003.14998626709ms\n",
      "24885\n",
      "\n",
      "\n",
      "batch 389/848 loss: 0.23377276957035065 accuracy: 0.921875 time: 35921.28801345825ms\n",
      "24948\n",
      "\n",
      "\n",
      "batch 390/848 loss: 0.2472001016139984 accuracy: 0.9375 time: 37354.105949401855ms\n",
      "25011\n",
      "\n",
      "\n",
      "batch 391/848 loss: 0.3536321818828583 accuracy: 0.875 time: 35812.30688095093ms\n",
      "25074\n",
      "\n",
      "\n",
      "batch 392/848 loss: 0.4347190260887146 accuracy: 0.859375 time: 36526.69382095337ms\n",
      "25137\n",
      "\n",
      "\n",
      "batch 393/848 loss: 0.4232644736766815 accuracy: 0.875 time: 38437.56818771362ms\n",
      "25200\n",
      "\n",
      "\n",
      "batch 394/848 loss: 0.492919921875 accuracy: 0.859375 time: 37283.96487236023ms\n",
      "25263\n",
      "\n",
      "\n",
      "batch 395/848 loss: 0.4937971234321594 accuracy: 0.84375 time: 36535.66002845764ms\n",
      "25326\n",
      "\n",
      "\n",
      "batch 396/848 loss: 0.2495066225528717 accuracy: 0.90625 time: 36565.109968185425ms\n",
      "25389\n",
      "\n",
      "\n",
      "batch 397/848 loss: 0.28077390789985657 accuracy: 0.875 time: 38182.2350025177ms\n",
      "25452\n",
      "\n",
      "\n",
      "batch 398/848 loss: 0.21335121989250183 accuracy: 0.953125 time: 36499.85384941101ms\n",
      "25515\n",
      "\n",
      "\n",
      "batch 399/848 loss: 0.17189347743988037 accuracy: 0.953125 time: 36287.935972213745ms\n",
      "25578\n",
      "\n",
      "\n",
      "batch 400/848 loss: 0.28410711884498596 accuracy: 0.9375 time: 38387.24899291992ms\n",
      "25641\n",
      "\n",
      "\n",
      "batch 401/848 loss: 0.33996662497520447 accuracy: 0.921875 time: 36375.24390220642ms\n",
      "25704\n",
      "\n",
      "\n",
      "batch 402/848 loss: 0.2995914816856384 accuracy: 0.9375 time: 35565.2379989624ms\n",
      "25767\n",
      "\n",
      "\n",
      "batch 403/848 loss: 0.7393257021903992 accuracy: 0.8125 time: 36012.97092437744ms\n",
      "25830\n",
      "\n",
      "\n",
      "batch 404/848 loss: 0.3406848907470703 accuracy: 0.90625 time: 36100.67081451416ms\n",
      "25893\n",
      "\n",
      "\n",
      "batch 405/848 loss: 0.43323057889938354 accuracy: 0.84375 time: 36272.735834121704ms\n",
      "25956\n",
      "\n",
      "\n",
      "batch 406/848 loss: 0.3566763997077942 accuracy: 0.890625 time: 36140.0351524353ms\n",
      "26019\n",
      "\n",
      "\n",
      "batch 407/848 loss: 0.29374074935913086 accuracy: 0.890625 time: 36417.99592971802ms\n",
      "26082\n",
      "\n",
      "\n",
      "batch 408/848 loss: 0.2541578710079193 accuracy: 0.9375 time: 37567.83699989319ms\n",
      "26145\n",
      "\n",
      "\n",
      "batch 409/848 loss: 0.10352782160043716 accuracy: 0.953125 time: 36700.70815086365ms\n",
      "26208\n",
      "\n",
      "\n",
      "batch 410/848 loss: 0.3168098032474518 accuracy: 0.90625 time: 36645.59006690979ms\n",
      "26271\n",
      "\n",
      "\n",
      "batch 411/848 loss: 0.5160313844680786 accuracy: 0.828125 time: 35436.82789802551ms\n",
      "26334\n",
      "\n",
      "\n",
      "batch 412/848 loss: 0.3097815215587616 accuracy: 0.875 time: 35930.10902404785ms\n",
      "26397\n",
      "\n",
      "\n",
      "batch 413/848 loss: 0.22796957194805145 accuracy: 0.953125 time: 37031.76283836365ms\n",
      "26460\n",
      "\n",
      "\n",
      "batch 414/848 loss: 0.4245617091655731 accuracy: 0.890625 time: 36373.36993217468ms\n",
      "26523\n",
      "\n",
      "\n",
      "batch 415/848 loss: 0.2638712525367737 accuracy: 0.921875 time: 36821.36797904968ms\n",
      "26586\n",
      "\n",
      "\n",
      "batch 416/848 loss: 0.23641230165958405 accuracy: 0.875 time: 36886.2988948822ms\n",
      "26649\n",
      "\n",
      "\n",
      "batch 417/848 loss: 0.2744981050491333 accuracy: 0.859375 time: 37796.99206352234ms\n",
      "26712\n",
      "\n",
      "\n",
      "batch 418/848 loss: 0.6173188090324402 accuracy: 0.890625 time: 35931.7741394043ms\n",
      "26775\n",
      "\n",
      "\n",
      "batch 419/848 loss: 0.2869926989078522 accuracy: 0.9375 time: 36155.25007247925ms\n",
      "26838\n",
      "\n",
      "\n",
      "batch 420/848 loss: 0.1316974014043808 accuracy: 0.96875 time: 36792.29497909546ms\n",
      "26901\n",
      "\n",
      "\n",
      "batch 421/848 loss: 0.26890280842781067 accuracy: 0.921875 time: 35809.05103683472ms\n",
      "26964\n",
      "\n",
      "\n",
      "batch 422/848 loss: 0.2819620668888092 accuracy: 0.859375 time: 35515.61903953552ms\n",
      "27027\n",
      "\n",
      "\n",
      "batch 423/848 loss: 0.41250407695770264 accuracy: 0.9375 time: 37190.83905220032ms\n",
      "27090\n",
      "\n",
      "\n",
      "batch 424/848 loss: 0.07077724486589432 accuracy: 0.984375 time: 35658.401012420654ms\n",
      "27153\n",
      "\n",
      "\n",
      "batch 425/848 loss: 0.18230664730072021 accuracy: 0.921875 time: 36295.75705528259ms\n",
      "27216\n",
      "\n",
      "\n",
      "batch 426/848 loss: 0.3977031111717224 accuracy: 0.90625 time: 36401.484966278076ms\n",
      "27279\n",
      "\n",
      "\n",
      "batch 427/848 loss: 0.33617478609085083 accuracy: 0.890625 time: 44595.20220756531ms\n",
      "27342\n",
      "\n",
      "\n",
      "batch 428/848 loss: 0.308721125125885 accuracy: 0.921875 time: 36833.264112472534ms\n",
      "27405\n",
      "\n",
      "\n",
      "batch 429/848 loss: 0.22721561789512634 accuracy: 0.9375 time: 36260.202169418335ms\n",
      "27468\n",
      "\n",
      "\n",
      "batch 430/848 loss: 0.4559858441352844 accuracy: 0.890625 time: 37277.74381637573ms\n",
      "27531\n",
      "\n",
      "\n",
      "batch 431/848 loss: 0.21990829706192017 accuracy: 0.921875 time: 37156.09288215637ms\n",
      "27594\n",
      "\n",
      "\n",
      "batch 432/848 loss: 0.3123520016670227 accuracy: 0.90625 time: 36416.17012023926ms\n",
      "27657\n",
      "\n",
      "\n",
      "batch 433/848 loss: 0.26073434948921204 accuracy: 0.90625 time: 36771.32797241211ms\n",
      "27720\n",
      "\n",
      "\n",
      "batch 434/848 loss: 0.12148876488208771 accuracy: 0.953125 time: 36182.24501609802ms\n",
      "27783\n",
      "\n",
      "\n",
      "batch 435/848 loss: 0.4768674075603485 accuracy: 0.84375 time: 38370.59712409973ms\n",
      "27846\n",
      "\n",
      "\n",
      "batch 436/848 loss: 0.3206871747970581 accuracy: 0.890625 time: 36907.163858413696ms\n",
      "27909\n",
      "\n",
      "\n",
      "batch 437/848 loss: 0.3663862943649292 accuracy: 0.859375 time: 35789.57509994507ms\n",
      "27972\n",
      "\n",
      "\n",
      "batch 438/848 loss: 0.314626544713974 accuracy: 0.890625 time: 36159.0301990509ms\n",
      "28035\n",
      "\n",
      "\n",
      "batch 439/848 loss: 0.636361837387085 accuracy: 0.8125 time: 38434.3159198761ms\n",
      "28098\n",
      "\n",
      "\n",
      "batch 440/848 loss: 0.28561556339263916 accuracy: 0.921875 time: 36417.06299781799ms\n",
      "28161\n",
      "\n",
      "\n",
      "batch 441/848 loss: 0.23018112778663635 accuracy: 0.921875 time: 36620.31817436218ms\n",
      "28224\n",
      "\n",
      "\n",
      "batch 441/848 loss: 0.18374872207641602 accuracy: 0.96875 time: 36766.28088951111ms\n",
      "28287\n",
      "\n",
      "\n",
      "batch 442/848 loss: 0.41803663969039917 accuracy: 0.890625 time: 36965.58880805969ms\n",
      "28350\n",
      "\n",
      "\n",
      "batch 443/848 loss: 0.4047706425189972 accuracy: 0.90625 time: 35903.5758972168ms\n",
      "28413\n",
      "\n",
      "\n",
      "batch 444/848 loss: 0.48119813203811646 accuracy: 0.84375 time: 37585.5929851532ms\n",
      "28476\n",
      "\n",
      "\n",
      "batch 445/848 loss: 0.13113181293010712 accuracy: 0.984375 time: 35964.537143707275ms\n",
      "28539\n",
      "\n",
      "\n",
      "batch 446/848 loss: 0.19508317112922668 accuracy: 0.890625 time: 35723.90007972717ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28602\n",
      "\n",
      "\n",
      "batch 447/848 loss: 0.15509331226348877 accuracy: 0.953125 time: 36886.2419128418ms\n",
      "28665\n",
      "\n",
      "\n",
      "batch 448/848 loss: 0.3690362572669983 accuracy: 0.84375 time: 37888.782024383545ms\n",
      "28728\n",
      "\n",
      "\n",
      "batch 449/848 loss: 0.2999347448348999 accuracy: 0.921875 time: 36714.80894088745ms\n",
      "28791\n",
      "\n",
      "\n",
      "batch 450/848 loss: 0.4735127389431 accuracy: 0.890625 time: 37055.97805976868ms\n",
      "28854\n",
      "\n",
      "\n",
      "batch 451/848 loss: 0.5282702445983887 accuracy: 0.84375 time: 36743.03984642029ms\n",
      "28917\n",
      "\n",
      "\n",
      "batch 452/848 loss: 0.31164079904556274 accuracy: 0.921875 time: 36624.932050704956ms\n",
      "28980\n",
      "\n",
      "\n",
      "batch 453/848 loss: 0.24822178483009338 accuracy: 0.890625 time: 36591.55797958374ms\n",
      "29043\n",
      "\n",
      "\n",
      "batch 454/848 loss: 0.18081170320510864 accuracy: 0.96875 time: 36382.88998603821ms\n",
      "29106\n",
      "\n",
      "\n",
      "batch 455/848 loss: 0.15880286693572998 accuracy: 0.9375 time: 36113.02995681763ms\n",
      "29169\n",
      "\n",
      "\n",
      "batch 456/848 loss: 0.21365560591220856 accuracy: 0.9375 time: 36427.8290271759ms\n",
      "29232\n",
      "\n",
      "\n",
      "batch 457/848 loss: 0.22025668621063232 accuracy: 0.90625 time: 36802.740812301636ms\n",
      "29295\n",
      "\n",
      "\n",
      "batch 458/848 loss: 0.3362749516963959 accuracy: 0.890625 time: 36325.714111328125ms\n",
      "29358\n",
      "\n",
      "\n",
      "batch 459/848 loss: 0.37366676330566406 accuracy: 0.859375 time: 36477.97417640686ms\n",
      "29421\n",
      "\n",
      "\n",
      "batch 460/848 loss: 0.5469205975532532 accuracy: 0.90625 time: 518747.66087532043ms\n",
      "29484\n",
      "\n",
      "\n",
      "batch 461/848 loss: 0.27953770756721497 accuracy: 0.90625 time: 44617.91801452637ms\n",
      "29547\n",
      "\n",
      "\n",
      "batch 462/848 loss: 0.40428221225738525 accuracy: 0.875 time: 46583.52994918823ms\n",
      "29610\n",
      "\n",
      "\n",
      "batch 463/848 loss: 0.26809990406036377 accuracy: 0.890625 time: 42124.71604347229ms\n",
      "29673\n",
      "\n",
      "\n",
      "batch 464/848 loss: 0.08618707954883575 accuracy: 0.96875 time: 38822.4561214447ms\n",
      "29736\n",
      "\n",
      "\n",
      "batch 465/848 loss: 0.3706668019294739 accuracy: 0.9375 time: 36245.5849647522ms\n",
      "29799\n",
      "\n",
      "\n",
      "batch 466/848 loss: 0.29621922969818115 accuracy: 0.875 time: 36378.65710258484ms\n",
      "29862\n",
      "\n",
      "\n",
      "batch 467/848 loss: 0.7193355560302734 accuracy: 0.796875 time: 35474.49803352356ms\n",
      "29925\n",
      "\n",
      "\n",
      "batch 468/848 loss: 0.4307018518447876 accuracy: 0.859375 time: 35982.85794258118ms\n",
      "29988\n",
      "\n",
      "\n",
      "batch 469/848 loss: 0.17886465787887573 accuracy: 0.9375 time: 36908.6389541626ms\n",
      "30051\n",
      "\n",
      "\n",
      "batch 470/848 loss: 0.17026421427726746 accuracy: 0.90625 time: 37903.12910079956ms\n",
      "30114\n",
      "\n",
      "\n",
      "batch 471/848 loss: 0.23771978914737701 accuracy: 0.9375 time: 37069.34714317322ms\n",
      "30177\n",
      "\n",
      "\n",
      "batch 472/848 loss: 0.20209315419197083 accuracy: 0.953125 time: 37957.549810409546ms\n",
      "30240\n",
      "\n",
      "\n",
      "batch 473/848 loss: 0.3860216736793518 accuracy: 0.84375 time: 36104.119062423706ms\n",
      "30303\n",
      "\n",
      "\n",
      "batch 474/848 loss: 0.3377581536769867 accuracy: 0.90625 time: 34848.97685050964ms\n",
      "30366\n",
      "\n",
      "\n",
      "batch 475/848 loss: 0.09755916148424149 accuracy: 0.9375 time: 36732.92422294617ms\n",
      "30429\n",
      "\n",
      "\n",
      "batch 476/848 loss: 0.2764953374862671 accuracy: 0.875 time: 36836.687088012695ms\n",
      "30492\n",
      "\n",
      "\n",
      "batch 477/848 loss: 0.36416885256767273 accuracy: 0.890625 time: 37599.70998764038ms\n",
      "30555\n",
      "\n",
      "\n",
      "batch 478/848 loss: 0.13576103746891022 accuracy: 0.9375 time: 36271.42095565796ms\n",
      "30618\n",
      "\n",
      "\n",
      "batch 479/848 loss: 0.2230776697397232 accuracy: 0.9375 time: 36828.442096710205ms\n",
      "30681\n",
      "\n",
      "\n",
      "batch 480/848 loss: 0.1986190676689148 accuracy: 0.875 time: 36433.69102478027ms\n",
      "30744\n",
      "\n",
      "\n",
      "batch 481/848 loss: 0.15389931201934814 accuracy: 0.9375 time: 36933.68101119995ms\n",
      "30807\n",
      "\n",
      "\n",
      "batch 482/848 loss: 0.08473005890846252 accuracy: 0.984375 time: 35460.69407463074ms\n",
      "30870\n",
      "\n",
      "\n",
      "batch 483/848 loss: 0.26178890466690063 accuracy: 0.90625 time: 37922.566175460815ms\n",
      "30933\n",
      "\n",
      "\n",
      "batch 484/848 loss: 0.3300511837005615 accuracy: 0.859375 time: 36628.2320022583ms\n",
      "30996\n",
      "\n",
      "\n",
      "batch 485/848 loss: 0.35569050908088684 accuracy: 0.875 time: 36572.142124176025ms\n",
      "31059\n",
      "\n",
      "\n",
      "batch 486/848 loss: 0.5854513645172119 accuracy: 0.796875 time: 37722.49102592468ms\n",
      "31122\n",
      "\n",
      "\n",
      "batch 487/848 loss: 0.18246811628341675 accuracy: 0.9375 time: 38666.80383682251ms\n",
      "31185\n",
      "\n",
      "\n",
      "batch 488/848 loss: 0.3327002227306366 accuracy: 0.9375 time: 36692.64507293701ms\n",
      "31248\n",
      "\n",
      "\n",
      "batch 489/848 loss: 0.2599353790283203 accuracy: 0.921875 time: 37260.28394699097ms\n",
      "31311\n",
      "\n",
      "\n",
      "batch 490/848 loss: 0.1183152049779892 accuracy: 0.953125 time: 36796.47612571716ms\n",
      "31374\n",
      "\n",
      "\n",
      "batch 491/848 loss: 0.21979373693466187 accuracy: 0.921875 time: 36030.12704849243ms\n",
      "31437\n",
      "\n",
      "\n",
      "batch 492/848 loss: 0.4004572331905365 accuracy: 0.84375 time: 35669.7940826416ms\n",
      "31500\n",
      "\n",
      "\n",
      "batch 493/848 loss: 0.30674415826797485 accuracy: 0.90625 time: 38317.09098815918ms\n",
      "31563\n",
      "\n",
      "\n",
      "batch 494/848 loss: 0.5726523399353027 accuracy: 0.84375 time: 36037.20784187317ms\n",
      "31626\n",
      "\n",
      "\n",
      "batch 495/848 loss: 0.3111303150653839 accuracy: 0.921875 time: 36608.461141586304ms\n",
      "31689\n",
      "\n",
      "\n",
      "batch 496/848 loss: 0.4550691843032837 accuracy: 0.890625 time: 38248.085021972656ms\n",
      "31752\n",
      "\n",
      "\n",
      "batch 497/848 loss: 0.3009592890739441 accuracy: 0.859375 time: 37153.33294868469ms\n",
      "31815\n",
      "\n",
      "\n",
      "batch 498/848 loss: 0.15955087542533875 accuracy: 0.953125 time: 37217.40984916687ms\n",
      "31878\n",
      "\n",
      "\n",
      "batch 499/848 loss: 0.5080121755599976 accuracy: 0.890625 time: 37065.54293632507ms\n",
      "31941\n",
      "\n",
      "\n",
      "batch 500/848 loss: 0.24832314252853394 accuracy: 0.921875 time: 37017.19880104065ms\n",
      "32004\n",
      "\n",
      "\n",
      "batch 501/848 loss: 0.1503543257713318 accuracy: 0.96875 time: 37114.34102058411ms\n",
      "32067\n",
      "\n",
      "\n",
      "batch 502/848 loss: 0.18932975828647614 accuracy: 0.921875 time: 39657.833099365234ms\n",
      "32130\n",
      "\n",
      "\n",
      "batch 503/848 loss: 0.28569841384887695 accuracy: 0.90625 time: 37411.40389442444ms\n",
      "32193\n",
      "\n",
      "\n",
      "batch 504/848 loss: 0.24778801202774048 accuracy: 0.953125 time: 36389.081954956055ms\n",
      "32256\n",
      "\n",
      "\n",
      "batch 504/848 loss: 0.3430963456630707 accuracy: 0.890625 time: 36656.91685676575ms\n",
      "32319\n",
      "\n",
      "\n",
      "batch 505/848 loss: 0.5427743196487427 accuracy: 0.8125 time: 38004.64200973511ms\n",
      "32382\n",
      "\n",
      "\n",
      "batch 506/848 loss: 0.21517258882522583 accuracy: 0.875 time: 36453.980922698975ms\n",
      "32445\n",
      "\n",
      "\n",
      "batch 507/848 loss: 0.27651530504226685 accuracy: 0.890625 time: 35714.52188491821ms\n",
      "32508\n",
      "\n",
      "\n",
      "batch 508/848 loss: 0.4218941330909729 accuracy: 0.84375 time: 37204.7700881958ms\n",
      "32571\n",
      "\n",
      "\n",
      "batch 509/848 loss: 0.21149644255638123 accuracy: 0.9375 time: 35790.799140930176ms\n",
      "32634\n",
      "\n",
      "\n",
      "batch 510/848 loss: 0.148081973195076 accuracy: 0.953125 time: 35553.20906639099ms\n",
      "32697\n",
      "\n",
      "\n",
      "batch 511/848 loss: 0.365753173828125 accuracy: 0.90625 time: 36708.38284492493ms\n",
      "32760\n",
      "\n",
      "\n",
      "batch 512/848 loss: 0.14883753657341003 accuracy: 0.96875 time: 36252.77400016785ms\n",
      "32823\n",
      "\n",
      "\n",
      "batch 513/848 loss: 0.3778257966041565 accuracy: 0.875 time: 37992.64693260193ms\n",
      "32886\n",
      "\n",
      "\n",
      "batch 514/848 loss: 0.28159692883491516 accuracy: 0.921875 time: 37371.28210067749ms\n",
      "32949\n",
      "\n",
      "\n",
      "batch 515/848 loss: 0.4149984121322632 accuracy: 0.875 time: 36665.194034576416ms\n",
      "33012\n",
      "\n",
      "\n",
      "batch 516/848 loss: 0.261989951133728 accuracy: 0.921875 time: 39742.63906478882ms\n",
      "33075\n",
      "\n",
      "\n",
      "batch 517/848 loss: 0.13144727051258087 accuracy: 0.9375 time: 39362.94603347778ms\n",
      "33138\n",
      "\n",
      "\n",
      "batch 518/848 loss: 0.22035419940948486 accuracy: 0.890625 time: 36838.43398094177ms\n",
      "33201\n",
      "\n",
      "\n",
      "batch 519/848 loss: 0.2863155007362366 accuracy: 0.921875 time: 38939.302921295166ms\n",
      "33264\n",
      "\n",
      "\n",
      "batch 520/848 loss: 0.26575446128845215 accuracy: 0.890625 time: 37580.30104637146ms\n",
      "33327\n",
      "\n",
      "\n",
      "batch 521/848 loss: 0.2739903926849365 accuracy: 0.921875 time: 36870.87297439575ms\n",
      "33390\n",
      "\n",
      "\n",
      "batch 522/848 loss: 0.24155768752098083 accuracy: 0.953125 time: 42116.97697639465ms\n",
      "33453\n",
      "\n",
      "\n",
      "batch 523/848 loss: 0.10670831799507141 accuracy: 0.9375 time: 36382.33423233032ms\n",
      "33516\n",
      "\n",
      "\n",
      "batch 524/848 loss: 0.15477865934371948 accuracy: 0.890625 time: 38908.19001197815ms\n",
      "33579\n",
      "\n",
      "\n",
      "batch 525/848 loss: 0.533591628074646 accuracy: 0.890625 time: 37794.00897026062ms\n",
      "33642\n",
      "\n",
      "\n",
      "batch 526/848 loss: 0.19115160405635834 accuracy: 0.921875 time: 37530.730962753296ms\n",
      "33705\n",
      "\n",
      "\n",
      "batch 527/848 loss: 0.2456287145614624 accuracy: 0.921875 time: 36232.32102394104ms\n",
      "33768\n",
      "\n",
      "\n",
      "batch 528/848 loss: 0.23908214271068573 accuracy: 0.890625 time: 35560.68301200867ms\n",
      "33831\n",
      "\n",
      "\n",
      "batch 529/848 loss: 0.419841468334198 accuracy: 0.890625 time: 37534.416913986206ms\n",
      "33894\n",
      "\n",
      "\n",
      "batch 530/848 loss: 0.08636161684989929 accuracy: 0.984375 time: 36876.869201660156ms\n",
      "33957\n",
      "\n",
      "\n",
      "batch 531/848 loss: 0.27497267723083496 accuracy: 0.890625 time: 35851.16100311279ms\n",
      "34020\n",
      "\n",
      "\n",
      "batch 532/848 loss: 0.410419225692749 accuracy: 0.875 time: 36151.118993759155ms\n",
      "34083\n",
      "\n",
      "\n",
      "batch 533/848 loss: 0.4233167767524719 accuracy: 0.90625 time: 35597.74708747864ms\n",
      "34146\n",
      "\n",
      "\n",
      "batch 534/848 loss: 0.27654993534088135 accuracy: 0.921875 time: 37655.714988708496ms\n",
      "34209\n",
      "\n",
      "\n",
      "batch 535/848 loss: 0.30671751499176025 accuracy: 0.90625 time: 37029.22701835632ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34272\n",
      "\n",
      "\n",
      "batch 536/848 loss: 0.24709677696228027 accuracy: 0.890625 time: 36840.538024902344ms\n",
      "34335\n",
      "\n",
      "\n",
      "batch 537/848 loss: 0.09726863354444504 accuracy: 0.953125 time: 36596.988916397095ms\n",
      "34398\n",
      "\n",
      "\n",
      "batch 538/848 loss: 0.6007808446884155 accuracy: 0.875 time: 35439.39113616943ms\n",
      "34461\n",
      "\n",
      "\n",
      "batch 539/848 loss: 0.3396815359592438 accuracy: 0.890625 time: 36785.603046417236ms\n",
      "34524\n",
      "\n",
      "\n",
      "batch 540/848 loss: 0.46035897731781006 accuracy: 0.90625 time: 36613.044023513794ms\n",
      "34587\n",
      "\n",
      "\n",
      "batch 541/848 loss: 0.3291267454624176 accuracy: 0.90625 time: 36647.82500267029ms\n",
      "34650\n",
      "\n",
      "\n",
      "batch 542/848 loss: 0.4226551055908203 accuracy: 0.90625 time: 35934.942960739136ms\n",
      "34713\n",
      "\n",
      "\n",
      "batch 543/848 loss: 0.32177016139030457 accuracy: 0.890625 time: 35889.90902900696ms\n",
      "34776\n",
      "\n",
      "\n",
      "batch 544/848 loss: 0.28424763679504395 accuracy: 0.9375 time: 38426.59282684326ms\n",
      "34839\n",
      "\n",
      "\n",
      "batch 545/848 loss: 0.25501877069473267 accuracy: 0.890625 time: 37815.016984939575ms\n",
      "34902\n",
      "\n",
      "\n",
      "batch 546/848 loss: 0.2909088432788849 accuracy: 0.90625 time: 35659.343957901ms\n",
      "34965\n",
      "\n",
      "\n",
      "batch 547/848 loss: 0.3101279139518738 accuracy: 0.875 time: 37514.440059661865ms\n",
      "35028\n",
      "\n",
      "\n",
      "batch 548/848 loss: 0.23807063698768616 accuracy: 0.953125 time: 37164.94798660278ms\n",
      "35091\n",
      "\n",
      "\n",
      "batch 549/848 loss: 0.2912408113479614 accuracy: 0.9375 time: 35437.34288215637ms\n",
      "35154\n",
      "\n",
      "\n",
      "batch 550/848 loss: 0.500420093536377 accuracy: 0.875 time: 37338.59300613403ms\n",
      "35217\n",
      "\n",
      "\n",
      "batch 551/848 loss: 0.14970463514328003 accuracy: 0.96875 time: 36350.22497177124ms\n",
      "35280\n",
      "\n",
      "\n",
      "batch 552/848 loss: 0.12527717649936676 accuracy: 0.9375 time: 36593.316078186035ms\n",
      "35343\n",
      "\n",
      "\n",
      "batch 553/848 loss: 0.18820881843566895 accuracy: 0.96875 time: 35476.831912994385ms\n",
      "35406\n",
      "\n",
      "\n",
      "batch 554/848 loss: 0.2924080193042755 accuracy: 0.90625 time: 37334.919929504395ms\n",
      "35469\n",
      "\n",
      "\n",
      "batch 555/848 loss: 0.18850764632225037 accuracy: 0.9375 time: 38426.54204368591ms\n",
      "35532\n",
      "\n",
      "\n",
      "batch 556/848 loss: 0.08233132213354111 accuracy: 0.96875 time: 36476.46498680115ms\n",
      "35595\n",
      "\n",
      "\n",
      "batch 557/848 loss: 0.25301918387413025 accuracy: 0.875 time: 37103.951930999756ms\n",
      "35658\n",
      "\n",
      "\n",
      "batch 558/848 loss: 0.28566890954971313 accuracy: 0.90625 time: 35481.08005523682ms\n",
      "35721\n",
      "\n",
      "\n",
      "batch 559/848 loss: 0.2536409795284271 accuracy: 0.921875 time: 35810.46414375305ms\n",
      "35784\n",
      "\n",
      "\n",
      "batch 560/848 loss: 0.2897915244102478 accuracy: 0.90625 time: 36785.22300720215ms\n",
      "35847\n",
      "\n",
      "\n",
      "batch 561/848 loss: 0.3103802502155304 accuracy: 0.890625 time: 37686.830043792725ms\n",
      "35910\n",
      "\n",
      "\n",
      "batch 562/848 loss: 0.3729308247566223 accuracy: 0.890625 time: 36187.67809867859ms\n",
      "35973\n",
      "\n",
      "\n",
      "batch 563/848 loss: 0.32874345779418945 accuracy: 0.890625 time: 38159.72590446472ms\n",
      "36036\n",
      "\n",
      "\n",
      "batch 564/848 loss: 0.29351216554641724 accuracy: 0.90625 time: 35240.4990196228ms\n",
      "36099\n",
      "\n",
      "\n",
      "batch 565/848 loss: 0.3153693675994873 accuracy: 0.875 time: 36906.75187110901ms\n",
      "36162\n",
      "\n",
      "\n",
      "batch 566/848 loss: 0.15967640280723572 accuracy: 0.953125 time: 35927.39987373352ms\n",
      "36225\n",
      "\n",
      "\n",
      "batch 567/848 loss: 0.36923912167549133 accuracy: 0.90625 time: 37666.887044906616ms\n",
      "36288\n",
      "\n",
      "\n",
      "batch 567/848 loss: 0.1756928712129593 accuracy: 0.953125 time: 39019.956827163696ms\n",
      "36351\n",
      "\n",
      "\n",
      "batch 568/848 loss: 0.15470272302627563 accuracy: 0.9375 time: 35884.602069854736ms\n",
      "36414\n",
      "\n",
      "\n",
      "batch 569/848 loss: 0.2671154737472534 accuracy: 0.890625 time: 38147.60184288025ms\n",
      "36477\n",
      "\n",
      "\n",
      "batch 570/848 loss: 0.4078678488731384 accuracy: 0.890625 time: 35822.49999046326ms\n",
      "36540\n",
      "\n",
      "\n",
      "batch 571/848 loss: 0.23260365426540375 accuracy: 0.921875 time: 36694.20099258423ms\n",
      "36603\n",
      "\n",
      "\n",
      "batch 572/848 loss: 0.3810308575630188 accuracy: 0.890625 time: 35647.93086051941ms\n",
      "36666\n",
      "\n",
      "\n",
      "batch 573/848 loss: 0.2664055824279785 accuracy: 0.921875 time: 36633.51011276245ms\n",
      "36729\n",
      "\n",
      "\n",
      "batch 574/848 loss: 0.2779577970504761 accuracy: 0.921875 time: 42337.279081344604ms\n",
      "36792\n",
      "\n",
      "\n",
      "batch 575/848 loss: 0.1874009221792221 accuracy: 0.953125 time: 40257.79700279236ms\n",
      "36855\n",
      "\n",
      "\n",
      "batch 576/848 loss: 0.18060919642448425 accuracy: 0.921875 time: 35357.672929763794ms\n",
      "36918\n",
      "\n",
      "\n",
      "batch 577/848 loss: 0.47593510150909424 accuracy: 0.828125 time: 35738.871812820435ms\n",
      "36981\n",
      "\n",
      "\n",
      "batch 578/848 loss: 0.2798745036125183 accuracy: 0.890625 time: 38452.82196998596ms\n",
      "37044\n",
      "\n",
      "\n",
      "batch 579/848 loss: 0.1006784662604332 accuracy: 0.96875 time: 37920.125007629395ms\n",
      "37107\n",
      "\n",
      "\n",
      "batch 580/848 loss: 0.2933250069618225 accuracy: 0.90625 time: 35985.175132751465ms\n",
      "37170\n",
      "\n",
      "\n",
      "batch 581/848 loss: 0.6162303686141968 accuracy: 0.828125 time: 37871.25205993652ms\n",
      "37233\n",
      "\n",
      "\n",
      "batch 582/848 loss: 0.12671196460723877 accuracy: 0.9375 time: 37559.73410606384ms\n",
      "37296\n",
      "\n",
      "\n",
      "batch 583/848 loss: 0.2208620011806488 accuracy: 0.890625 time: 37474.17497634888ms\n",
      "37359\n",
      "\n",
      "\n",
      "batch 584/848 loss: 0.2518008351325989 accuracy: 0.921875 time: 36382.99202919006ms\n",
      "37422\n",
      "\n",
      "\n",
      "batch 585/848 loss: 0.3581332564353943 accuracy: 0.859375 time: 35807.0330619812ms\n",
      "37485\n",
      "\n",
      "\n",
      "batch 586/848 loss: 0.3116696774959564 accuracy: 0.90625 time: 36286.71407699585ms\n",
      "37548\n",
      "\n",
      "\n",
      "batch 587/848 loss: 0.27840346097946167 accuracy: 0.90625 time: 36759.113073349ms\n",
      "37611\n",
      "\n",
      "\n",
      "batch 588/848 loss: 0.425873339176178 accuracy: 0.890625 time: 37312.85786628723ms\n",
      "37674\n",
      "\n",
      "\n",
      "batch 589/848 loss: 0.5519754886627197 accuracy: 0.859375 time: 36789.156913757324ms\n",
      "37737\n",
      "\n",
      "\n",
      "batch 590/848 loss: 0.4986627697944641 accuracy: 0.8125 time: 36973.44708442688ms\n",
      "37800\n",
      "\n",
      "\n",
      "batch 591/848 loss: 0.32223838567733765 accuracy: 0.890625 time: 36362.68901824951ms\n",
      "37863\n",
      "\n",
      "\n",
      "batch 592/848 loss: 0.4756682515144348 accuracy: 0.875 time: 37471.97985649109ms\n",
      "37926\n",
      "\n",
      "\n",
      "batch 593/848 loss: 0.3031109571456909 accuracy: 0.875 time: 36225.76713562012ms\n",
      "37989\n",
      "\n",
      "\n",
      "batch 594/848 loss: 0.3469937741756439 accuracy: 0.921875 time: 36233.44707489014ms\n",
      "38052\n",
      "\n",
      "\n",
      "batch 595/848 loss: 0.16552209854125977 accuracy: 0.953125 time: 35786.47017478943ms\n",
      "38115\n",
      "\n",
      "\n",
      "batch 596/848 loss: 0.32169705629348755 accuracy: 0.90625 time: 35676.75495147705ms\n",
      "38178\n",
      "\n",
      "\n",
      "batch 597/848 loss: 0.38535112142562866 accuracy: 0.90625 time: 37378.02004814148ms\n",
      "38241\n",
      "\n",
      "\n",
      "batch 598/848 loss: 0.3276277780532837 accuracy: 0.875 time: 39348.97518157959ms\n",
      "38304\n",
      "\n",
      "\n",
      "batch 599/848 loss: 0.3383050858974457 accuracy: 0.890625 time: 35628.19004058838ms\n",
      "38367\n",
      "\n",
      "\n",
      "batch 600/848 loss: 0.3914586305618286 accuracy: 0.90625 time: 38154.67095375061ms\n",
      "38430\n",
      "\n",
      "\n",
      "batch 601/848 loss: 0.2654995620250702 accuracy: 0.90625 time: 43295.79401016235ms\n",
      "38493\n",
      "\n",
      "\n",
      "batch 602/848 loss: 0.6862472295761108 accuracy: 0.890625 time: 37662.11819648743ms\n",
      "38556\n",
      "\n",
      "\n",
      "batch 603/848 loss: 0.5008176565170288 accuracy: 0.890625 time: 37306.97798728943ms\n",
      "38619\n",
      "\n",
      "\n",
      "batch 604/848 loss: 0.40515419840812683 accuracy: 0.90625 time: 36819.98801231384ms\n",
      "38682\n",
      "\n",
      "\n",
      "batch 605/848 loss: 0.2993430495262146 accuracy: 0.90625 time: 37081.97999000549ms\n",
      "38745\n",
      "\n",
      "\n",
      "batch 606/848 loss: 0.2779110372066498 accuracy: 0.9375 time: 36870.622873306274ms\n",
      "38808\n",
      "\n",
      "\n",
      "batch 607/848 loss: 0.19871065020561218 accuracy: 0.953125 time: 37845.23391723633ms\n",
      "38871\n",
      "\n",
      "\n",
      "batch 608/848 loss: 0.18877379596233368 accuracy: 0.921875 time: 36323.813915252686ms\n",
      "38934\n",
      "\n",
      "\n",
      "batch 609/848 loss: 0.04734256863594055 accuracy: 0.984375 time: 38293.26510429382ms\n",
      "38997\n",
      "\n",
      "\n",
      "batch 610/848 loss: 0.15268391370773315 accuracy: 0.953125 time: 37522.932052612305ms\n",
      "39060\n",
      "\n",
      "\n",
      "batch 611/848 loss: 0.25835293531417847 accuracy: 0.921875 time: 36190.61613082886ms\n",
      "39123\n",
      "\n",
      "\n",
      "batch 612/848 loss: 0.3391849100589752 accuracy: 0.890625 time: 36207.05008506775ms\n",
      "39186\n",
      "\n",
      "\n",
      "batch 613/848 loss: 0.2505105137825012 accuracy: 0.90625 time: 35658.36405754089ms\n",
      "39249\n",
      "\n",
      "\n",
      "batch 614/848 loss: 0.22553007304668427 accuracy: 0.90625 time: 37647.119998931885ms\n",
      "39312\n",
      "\n",
      "\n",
      "batch 615/848 loss: 0.348295122385025 accuracy: 0.90625 time: 37013.44323158264ms\n",
      "39375\n",
      "\n",
      "\n",
      "batch 616/848 loss: 0.07419868558645248 accuracy: 0.984375 time: 37223.29092025757ms\n",
      "39438\n",
      "\n",
      "\n",
      "batch 617/848 loss: 0.274448424577713 accuracy: 0.90625 time: 37379.28295135498ms\n",
      "39501\n",
      "\n",
      "\n",
      "batch 618/848 loss: 0.4122118353843689 accuracy: 0.859375 time: 37357.836961746216ms\n",
      "39564\n",
      "\n",
      "\n",
      "batch 619/848 loss: 0.3174317181110382 accuracy: 0.84375 time: 36394.25587654114ms\n",
      "39627\n",
      "\n",
      "\n",
      "batch 620/848 loss: 0.41029006242752075 accuracy: 0.84375 time: 36438.93504142761ms\n",
      "39690\n",
      "\n",
      "\n",
      "batch 621/848 loss: 0.1800684779882431 accuracy: 0.890625 time: 37703.69911193848ms\n",
      "39753\n",
      "\n",
      "\n",
      "batch 622/848 loss: 0.39507338404655457 accuracy: 0.890625 time: 37937.39700317383ms\n",
      "39816\n",
      "\n",
      "\n",
      "batch 623/848 loss: 0.2612515687942505 accuracy: 0.9375 time: 40552.659034729004ms\n",
      "39879\n",
      "\n",
      "\n",
      "batch 624/848 loss: 0.2796602249145508 accuracy: 0.921875 time: 36855.84306716919ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39942\n",
      "\n",
      "\n",
      "batch 625/848 loss: 0.37616661190986633 accuracy: 0.921875 time: 37181.04100227356ms\n",
      "40005\n",
      "\n",
      "\n",
      "batch 626/848 loss: 0.25482791662216187 accuracy: 0.921875 time: 36317.96097755432ms\n",
      "40068\n",
      "\n",
      "\n",
      "batch 627/848 loss: 0.20826157927513123 accuracy: 0.953125 time: 39140.37489891052ms\n",
      "40131\n",
      "\n",
      "\n",
      "batch 628/848 loss: 0.27334439754486084 accuracy: 0.90625 time: 38573.795795440674ms\n",
      "40194\n",
      "\n",
      "\n",
      "batch 629/848 loss: 0.347217321395874 accuracy: 0.890625 time: 36253.83496284485ms\n",
      "40257\n",
      "\n",
      "\n",
      "batch 630/848 loss: 0.21348294615745544 accuracy: 0.953125 time: 38544.12508010864ms\n",
      "40320\n",
      "\n",
      "\n",
      "batch 630/848 loss: 0.24201659858226776 accuracy: 0.90625 time: 38064.89300727844ms\n",
      "40383\n",
      "\n",
      "\n",
      "batch 631/848 loss: 0.28172600269317627 accuracy: 0.921875 time: 36755.85317611694ms\n",
      "40446\n",
      "\n",
      "\n",
      "batch 632/848 loss: 0.2797870337963104 accuracy: 0.921875 time: 37178.21907997131ms\n",
      "40509\n",
      "\n",
      "\n",
      "batch 633/848 loss: 0.17404215037822723 accuracy: 0.953125 time: 36433.2709312439ms\n",
      "40572\n",
      "\n",
      "\n",
      "batch 634/848 loss: 0.3038208484649658 accuracy: 0.90625 time: 36773.42104911804ms\n",
      "40635\n",
      "\n",
      "\n",
      "batch 635/848 loss: 0.1983126699924469 accuracy: 0.921875 time: 36782.848834991455ms\n",
      "40698\n",
      "\n",
      "\n",
      "batch 636/848 loss: 0.31906047463417053 accuracy: 0.9375 time: 35983.587980270386ms\n",
      "40761\n",
      "\n",
      "\n",
      "batch 637/848 loss: 0.28938937187194824 accuracy: 0.921875 time: 35947.612047195435ms\n",
      "40824\n",
      "\n",
      "\n",
      "batch 638/848 loss: 0.37108564376831055 accuracy: 0.859375 time: 36507.07507133484ms\n",
      "40887\n",
      "\n",
      "\n",
      "batch 639/848 loss: 0.5754003524780273 accuracy: 0.875 time: 39056.59103393555ms\n",
      "40950\n",
      "\n",
      "\n",
      "batch 640/848 loss: 0.3518387973308563 accuracy: 0.9375 time: 36416.6259765625ms\n",
      "41013\n",
      "\n",
      "\n",
      "batch 641/848 loss: 0.11100748926401138 accuracy: 0.96875 time: 35778.81383895874ms\n",
      "41076\n",
      "\n",
      "\n",
      "batch 642/848 loss: 0.24461838603019714 accuracy: 0.875 time: 36195.52206993103ms\n",
      "41139\n",
      "\n",
      "\n",
      "batch 643/848 loss: 0.22329026460647583 accuracy: 0.921875 time: 39153.06496620178ms\n",
      "41202\n",
      "\n",
      "\n",
      "batch 644/848 loss: 0.19418670237064362 accuracy: 0.9375 time: 36021.677017211914ms\n",
      "41265\n",
      "\n",
      "\n",
      "batch 645/848 loss: 0.6748039722442627 accuracy: 0.796875 time: 37145.62487602234ms\n",
      "41328\n",
      "\n",
      "\n",
      "batch 646/848 loss: 0.42645716667175293 accuracy: 0.875 time: 37898.552894592285ms\n",
      "41391\n",
      "\n",
      "\n",
      "batch 647/848 loss: 0.3971303105354309 accuracy: 0.859375 time: 38188.60101699829ms\n",
      "41454\n",
      "\n",
      "\n",
      "batch 648/848 loss: 0.1475275307893753 accuracy: 0.9375 time: 35593.36495399475ms\n",
      "41517\n",
      "\n",
      "\n",
      "batch 649/848 loss: 0.36730319261550903 accuracy: 0.875 time: 35874.428033828735ms\n",
      "41580\n",
      "\n",
      "\n",
      "batch 650/848 loss: 0.12272477895021439 accuracy: 0.953125 time: 36320.10817527771ms\n",
      "41643\n",
      "\n",
      "\n",
      "batch 651/848 loss: 0.5283156633377075 accuracy: 0.890625 time: 37117.84791946411ms\n",
      "41706\n",
      "\n",
      "\n",
      "batch 652/848 loss: 0.3736518323421478 accuracy: 0.828125 time: 36311.03205680847ms\n",
      "41769\n",
      "\n",
      "\n",
      "batch 653/848 loss: 0.1831953227519989 accuracy: 0.921875 time: 35826.93600654602ms\n",
      "41832\n",
      "\n",
      "\n",
      "batch 654/848 loss: 0.11149922013282776 accuracy: 0.953125 time: 38529.0949344635ms\n",
      "41895\n",
      "\n",
      "\n",
      "batch 655/848 loss: 0.4065561592578888 accuracy: 0.890625 time: 36732.30600357056ms\n",
      "41958\n",
      "\n",
      "\n",
      "batch 656/848 loss: 0.1867857277393341 accuracy: 0.921875 time: 37039.072036743164ms\n",
      "42021\n",
      "\n",
      "\n",
      "batch 657/848 loss: 0.2003415822982788 accuracy: 0.9375 time: 36960.439920425415ms\n",
      "42084\n",
      "\n",
      "\n",
      "batch 658/848 loss: 0.21030321717262268 accuracy: 0.953125 time: 36207.452058792114ms\n",
      "42147\n",
      "\n",
      "\n",
      "batch 659/848 loss: 0.19294726848602295 accuracy: 0.921875 time: 35450.7999420166ms\n",
      "42210\n",
      "\n",
      "\n",
      "batch 660/848 loss: 0.18481075763702393 accuracy: 0.953125 time: 35610.599994659424ms\n",
      "42273\n",
      "\n",
      "\n",
      "batch 661/848 loss: 0.09140920639038086 accuracy: 0.984375 time: 36921.47493362427ms\n",
      "42336\n",
      "\n",
      "\n",
      "batch 662/848 loss: 0.4796757102012634 accuracy: 0.90625 time: 37274.163007736206ms\n",
      "42399\n",
      "\n",
      "\n",
      "batch 663/848 loss: 0.11004456877708435 accuracy: 0.96875 time: 36374.499797821045ms\n",
      "42462\n",
      "\n",
      "\n",
      "batch 664/848 loss: 0.39150452613830566 accuracy: 0.890625 time: 36313.17710876465ms\n",
      "42525\n",
      "\n",
      "\n",
      "batch 665/848 loss: 0.1716083288192749 accuracy: 0.953125 time: 35961.19809150696ms\n",
      "42588\n",
      "\n",
      "\n",
      "batch 666/848 loss: 0.22510461509227753 accuracy: 0.921875 time: 36427.340030670166ms\n",
      "42651\n",
      "\n",
      "\n",
      "batch 667/848 loss: 0.24828675389289856 accuracy: 0.921875 time: 36409.239053726196ms\n",
      "42714\n",
      "\n",
      "\n",
      "batch 668/848 loss: 0.05419051647186279 accuracy: 0.984375 time: 36514.64295387268ms\n",
      "42777\n",
      "\n",
      "\n",
      "batch 669/848 loss: 0.5209904313087463 accuracy: 0.875 time: 36092.83995628357ms\n",
      "42840\n",
      "\n",
      "\n",
      "batch 670/848 loss: 0.36300966143608093 accuracy: 0.875 time: 37835.74318885803ms\n",
      "42903\n",
      "\n",
      "\n",
      "batch 671/848 loss: 0.3062085509300232 accuracy: 0.90625 time: 37715.05093574524ms\n",
      "42966\n",
      "\n",
      "\n",
      "batch 672/848 loss: 0.22495733201503754 accuracy: 0.953125 time: 36994.97318267822ms\n",
      "43029\n",
      "\n",
      "\n",
      "batch 673/848 loss: 0.2985296845436096 accuracy: 0.859375 time: 38999.008893966675ms\n",
      "43092\n",
      "\n",
      "\n",
      "batch 674/848 loss: 0.19962987303733826 accuracy: 0.9375 time: 36672.14798927307ms\n",
      "43155\n",
      "\n",
      "\n",
      "batch 675/848 loss: 0.3927759528160095 accuracy: 0.890625 time: 36053.27892303467ms\n",
      "43218\n",
      "\n",
      "\n",
      "batch 676/848 loss: 0.26377999782562256 accuracy: 0.921875 time: 36547.73998260498ms\n",
      "43281\n",
      "\n",
      "\n",
      "batch 677/848 loss: 0.23596662282943726 accuracy: 0.90625 time: 39418.16282272339ms\n",
      "43344\n",
      "\n",
      "\n",
      "batch 678/848 loss: 0.21757522225379944 accuracy: 0.921875 time: 36429.43477630615ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bdd75529c6d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch {}/{} loss: {} accuracy: {} time: {}ms'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_index\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnice_n\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0, epochs) :\n",
    "    current_index = 0\n",
    "    \n",
    "    while current_index + batch_size < len(image_data_list)*0.8 :\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(current_index)\n",
    "        print('\\n')\n",
    "        b,l = get_batch()\n",
    "        \n",
    "        loss,accuracy = customVggModel.train_on_batch(b, l)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print('batch {}/{} loss: {} accuracy: {} time: {}ms'.format(int(current_index / batch_size), int(nice_n / batch_size), loss, accuracy, 1000 * (end_time - start_time)), flush=True)\n",
    "        \n",
    "    print('epoch {}/{}'.format(i,epoch))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 678/848 loss: 0.21757522225379944 accuracy: 0.921875 time: 36429.43477630615ms\n",
      "epoch 0/2\n"
     ]
    }
   ],
   "source": [
    "print('batch {}/{} loss: {} accuracy: {} time: {}ms'.format(int(current_index / batch_size), int(nice_n / batch_size), loss, accuracy, 1000 * (end_time - start_time)), flush=True)\n",
    "\n",
    "print('epoch {}/{}'.format(i,epochs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43392\n"
     ]
    }
   ],
   "source": [
    "print(batch_size*678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch score: 0.40006518\n",
      "Test batch accuracy: 0.890625\n",
      "43470\n",
      "\n",
      "\n",
      "sum accuracy-0.890625 sum loss-0.40006518363952637\n",
      "Test batch score: 0.5021095\n",
      "Test batch accuracy: 0.859375\n",
      "43533\n",
      "\n",
      "\n",
      "sum accuracy-1.75 sum loss-0.902174711227417\n",
      "Test batch score: 0.5546156\n",
      "Test batch accuracy: 0.859375\n",
      "43596\n",
      "\n",
      "\n",
      "sum accuracy-2.609375 sum loss-1.4567903280258179\n",
      "Test batch score: 0.10748383\n",
      "Test batch accuracy: 0.953125\n",
      "43659\n",
      "\n",
      "\n",
      "sum accuracy-3.5625 sum loss-1.5642741546034813\n",
      "Test batch score: 0.38090116\n",
      "Test batch accuracy: 0.921875\n",
      "43722\n",
      "\n",
      "\n",
      "sum accuracy-4.484375 sum loss-1.9451753124594688\n",
      "Test batch score: 0.14298524\n",
      "Test batch accuracy: 0.9375\n",
      "43785\n",
      "\n",
      "\n",
      "sum accuracy-5.421875 sum loss-2.088160552084446\n",
      "Test batch score: 0.39494002\n",
      "Test batch accuracy: 0.859375\n",
      "43848\n",
      "\n",
      "\n",
      "sum accuracy-6.28125 sum loss-2.4831005707383156\n",
      "Test batch score: 0.32085675\n",
      "Test batch accuracy: 0.890625\n",
      "43911\n",
      "\n",
      "\n",
      "sum accuracy-7.171875 sum loss-2.8039573207497597\n",
      "Test batch score: 0.31634027\n",
      "Test batch accuracy: 0.90625\n",
      "43974\n",
      "\n",
      "\n",
      "sum accuracy-8.078125 sum loss-3.1202975884079933\n",
      "Test batch score: 0.26749274\n",
      "Test batch accuracy: 0.875\n",
      "44037\n",
      "\n",
      "\n",
      "sum accuracy-8.953125 sum loss-3.3877903297543526\n",
      "Test batch score: 0.16816226\n",
      "Test batch accuracy: 0.9375\n",
      "44100\n",
      "\n",
      "\n",
      "sum accuracy-9.890625 sum loss-3.555952586233616\n",
      "Test batch score: 0.32661286\n",
      "Test batch accuracy: 0.90625\n",
      "44163\n",
      "\n",
      "\n",
      "sum accuracy-10.796875 sum loss-3.8825654461979866\n",
      "Test batch score: 0.20198083\n",
      "Test batch accuracy: 0.921875\n",
      "44226\n",
      "\n",
      "\n",
      "sum accuracy-11.71875 sum loss-4.084546275436878\n",
      "Test batch score: 0.2119239\n",
      "Test batch accuracy: 0.921875\n",
      "44289\n",
      "\n",
      "\n",
      "sum accuracy-12.640625 sum loss-4.296470172703266\n",
      "Test batch score: 0.5798235\n",
      "Test batch accuracy: 0.890625\n",
      "44352\n",
      "\n",
      "\n",
      "sum accuracy-13.53125 sum loss-4.876293666660786\n",
      "Test batch score: 0.16943654\n",
      "Test batch accuracy: 0.921875\n",
      "44415\n",
      "\n",
      "\n",
      "sum accuracy-14.453125 sum loss-5.045730210840702\n",
      "Test batch score: 0.1456416\n",
      "Test batch accuracy: 0.9375\n",
      "44478\n",
      "\n",
      "\n",
      "sum accuracy-15.390625 sum loss-5.1913718059659\n",
      "Test batch score: 0.3018089\n",
      "Test batch accuracy: 0.9375\n",
      "44541\n",
      "\n",
      "\n",
      "sum accuracy-16.328125 sum loss-5.493180699646473\n",
      "Test batch score: 0.35651165\n",
      "Test batch accuracy: 0.921875\n",
      "44604\n",
      "\n",
      "\n",
      "sum accuracy-17.25 sum loss-5.849692352116108\n",
      "Test batch score: 0.24263239\n",
      "Test batch accuracy: 0.890625\n",
      "44667\n",
      "\n",
      "\n",
      "sum accuracy-18.140625 sum loss-6.0923247411847115\n",
      "Test batch score: 0.5390421\n",
      "Test batch accuracy: 0.859375\n",
      "44730\n",
      "\n",
      "\n",
      "sum accuracy-19.0 sum loss-6.631366856396198\n",
      "Test batch score: 0.51854515\n",
      "Test batch accuracy: 0.875\n",
      "44793\n",
      "\n",
      "\n",
      "sum accuracy-19.875 sum loss-7.149912007153034\n",
      "Test batch score: 0.22863436\n",
      "Test batch accuracy: 0.890625\n",
      "44856\n",
      "\n",
      "\n",
      "sum accuracy-20.765625 sum loss-7.378546364605427\n",
      "Test batch score: 0.4839293\n",
      "Test batch accuracy: 0.859375\n",
      "44919\n",
      "\n",
      "\n",
      "sum accuracy-21.625 sum loss-7.862475670874119\n",
      "Test batch score: 0.5393827\n",
      "Test batch accuracy: 0.859375\n",
      "44982\n",
      "\n",
      "\n",
      "sum accuracy-22.484375 sum loss-8.401858367025852\n",
      "Test batch score: 0.5129168\n",
      "Test batch accuracy: 0.890625\n",
      "45045\n",
      "\n",
      "\n",
      "sum accuracy-23.375 sum loss-8.914775170385838\n",
      "Test batch score: 0.26092586\n",
      "Test batch accuracy: 0.875\n",
      "45108\n",
      "\n",
      "\n",
      "sum accuracy-24.25 sum loss-9.175701029598713\n",
      "Test batch score: 0.16696967\n",
      "Test batch accuracy: 0.9375\n",
      "45171\n",
      "\n",
      "\n",
      "sum accuracy-25.1875 sum loss-9.342670701444149\n",
      "Test batch score: 0.2445288\n",
      "Test batch accuracy: 0.9375\n",
      "45234\n",
      "\n",
      "\n",
      "sum accuracy-26.125 sum loss-9.587199501693249\n",
      "Test batch score: 0.2917056\n",
      "Test batch accuracy: 0.921875\n",
      "45297\n",
      "\n",
      "\n",
      "sum accuracy-27.046875 sum loss-9.878905110061169\n",
      "Test batch score: 0.33961844\n",
      "Test batch accuracy: 0.90625\n",
      "45360\n",
      "\n",
      "\n",
      "sum accuracy-27.953125 sum loss-10.218523554503918\n",
      "Test batch score: 0.7127366\n",
      "Test batch accuracy: 0.84375\n",
      "45423\n",
      "\n",
      "\n",
      "sum accuracy-28.796875 sum loss-10.931260161101818\n",
      "Test batch score: 0.24280638\n",
      "Test batch accuracy: 0.90625\n",
      "45486\n",
      "\n",
      "\n",
      "sum accuracy-29.703125 sum loss-11.174066536128521\n",
      "Test batch score: 0.31172132\n",
      "Test batch accuracy: 0.890625\n",
      "45549\n",
      "\n",
      "\n",
      "sum accuracy-30.59375 sum loss-11.485787861049175\n",
      "Test batch score: 0.30859637\n",
      "Test batch accuracy: 0.890625\n",
      "45612\n",
      "\n",
      "\n",
      "sum accuracy-31.484375 sum loss-11.794384233653545\n",
      "Test batch score: 0.15622275\n",
      "Test batch accuracy: 0.953125\n",
      "45675\n",
      "\n",
      "\n",
      "sum accuracy-32.4375 sum loss-11.950606979429722\n",
      "Test batch score: 0.4861293\n",
      "Test batch accuracy: 0.875\n",
      "45738\n",
      "\n",
      "\n",
      "sum accuracy-33.3125 sum loss-12.436736293137074\n",
      "Test batch score: 0.21724364\n",
      "Test batch accuracy: 0.921875\n",
      "45801\n",
      "\n",
      "\n",
      "sum accuracy-34.234375 sum loss-12.653979934751987\n",
      "Test batch score: 0.083435535\n",
      "Test batch accuracy: 0.984375\n",
      "45864\n",
      "\n",
      "\n",
      "sum accuracy-35.21875 sum loss-12.737415470182896\n",
      "Test batch score: 0.42375028\n",
      "Test batch accuracy: 0.890625\n",
      "45927\n",
      "\n",
      "\n",
      "sum accuracy-36.109375 sum loss-13.161165751516819\n",
      "Test batch score: 0.21726625\n",
      "Test batch accuracy: 0.890625\n",
      "45990\n",
      "\n",
      "\n",
      "sum accuracy-37.0 sum loss-13.378431998193264\n",
      "Test batch score: 0.2426095\n",
      "Test batch accuracy: 0.90625\n",
      "46053\n",
      "\n",
      "\n",
      "sum accuracy-37.90625 sum loss-13.621041499078274\n",
      "Test batch score: 0.35152858\n",
      "Test batch accuracy: 0.890625\n",
      "46116\n",
      "\n",
      "\n",
      "sum accuracy-38.796875 sum loss-13.972570084035397\n",
      "Test batch score: 0.24387446\n",
      "Test batch accuracy: 0.921875\n",
      "46179\n",
      "\n",
      "\n",
      "sum accuracy-39.71875 sum loss-14.216444544494152\n",
      "Test batch score: 0.14437076\n",
      "Test batch accuracy: 0.9375\n",
      "46242\n",
      "\n",
      "\n",
      "sum accuracy-40.65625 sum loss-14.360815308988094\n",
      "Test batch score: 0.30142325\n",
      "Test batch accuracy: 0.90625\n",
      "46305\n",
      "\n",
      "\n",
      "sum accuracy-41.5625 sum loss-14.66223856061697\n",
      "Test batch score: 0.47724298\n",
      "Test batch accuracy: 0.859375\n",
      "46368\n",
      "\n",
      "\n",
      "sum accuracy-42.421875 sum loss-15.139481537044048\n",
      "Test batch score: 0.2604035\n",
      "Test batch accuracy: 0.921875\n",
      "46431\n",
      "\n",
      "\n",
      "sum accuracy-43.34375 sum loss-15.399885050952435\n",
      "Test batch score: 0.50154126\n",
      "Test batch accuracy: 0.859375\n",
      "46494\n",
      "\n",
      "\n",
      "sum accuracy-44.203125 sum loss-15.901426307857037\n",
      "Test batch score: 0.3184594\n",
      "Test batch accuracy: 0.890625\n",
      "46557\n",
      "\n",
      "\n",
      "sum accuracy-45.09375 sum loss-16.21988569945097\n",
      "Test batch score: 0.55556834\n",
      "Test batch accuracy: 0.890625\n",
      "46620\n",
      "\n",
      "\n",
      "sum accuracy-45.984375 sum loss-16.77545403689146\n",
      "Test batch score: 0.18650919\n",
      "Test batch accuracy: 0.9375\n",
      "46683\n",
      "\n",
      "\n",
      "sum accuracy-46.921875 sum loss-16.96196322888136\n",
      "Test batch score: 0.39309323\n",
      "Test batch accuracy: 0.9375\n",
      "46746\n",
      "\n",
      "\n",
      "sum accuracy-47.859375 sum loss-17.355056457221508\n",
      "Test batch score: 0.42106247\n",
      "Test batch accuracy: 0.890625\n",
      "46809\n",
      "\n",
      "\n",
      "sum accuracy-48.75 sum loss-17.77611892670393\n",
      "Test batch score: 0.1646843\n",
      "Test batch accuracy: 0.953125\n",
      "46872\n",
      "\n",
      "\n",
      "sum accuracy-49.703125 sum loss-17.940803222358227\n",
      "Test batch score: 0.35928723\n",
      "Test batch accuracy: 0.84375\n",
      "46935\n",
      "\n",
      "\n",
      "sum accuracy-50.546875 sum loss-18.300090454518795\n",
      "Test batch score: 0.2416988\n",
      "Test batch accuracy: 0.9375\n",
      "46998\n",
      "\n",
      "\n",
      "sum accuracy-51.484375 sum loss-18.54178925603628\n",
      "Test batch score: 0.3854556\n",
      "Test batch accuracy: 0.875\n",
      "47061\n",
      "\n",
      "\n",
      "sum accuracy-52.359375 sum loss-18.9272448644042\n",
      "Test batch score: 0.3334247\n",
      "Test batch accuracy: 0.890625\n",
      "47124\n",
      "\n",
      "\n",
      "sum accuracy-53.25 sum loss-19.26066955178976\n",
      "Test batch score: 0.4389576\n",
      "Test batch accuracy: 0.890625\n",
      "47187\n",
      "\n",
      "\n",
      "sum accuracy-54.140625 sum loss-19.69962715357542\n",
      "Test batch score: 0.32257622\n",
      "Test batch accuracy: 0.921875\n",
      "47250\n",
      "\n",
      "\n",
      "sum accuracy-55.0625 sum loss-20.022203378379345\n",
      "Test batch score: 0.34804702\n",
      "Test batch accuracy: 0.890625\n",
      "47313\n",
      "\n",
      "\n",
      "sum accuracy-55.953125 sum loss-20.370250396430492\n",
      "Test batch score: 0.2694019\n",
      "Test batch accuracy: 0.90625\n",
      "47376\n",
      "\n",
      "\n",
      "sum accuracy-56.859375 sum loss-20.63965230435133\n",
      "Test batch score: 0.25817585\n",
      "Test batch accuracy: 0.9375\n",
      "47439\n",
      "\n",
      "\n",
      "sum accuracy-57.796875 sum loss-20.89782815426588\n",
      "Test batch score: 0.5559784\n",
      "Test batch accuracy: 0.875\n",
      "47502\n",
      "\n",
      "\n",
      "sum accuracy-58.671875 sum loss-21.453806571662426\n",
      "Test batch score: 0.31002423\n",
      "Test batch accuracy: 0.875\n",
      "47565\n",
      "\n",
      "\n",
      "sum accuracy-59.546875 sum loss-21.763830803334713\n",
      "Test batch score: 0.2271561\n",
      "Test batch accuracy: 0.9375\n",
      "47628\n",
      "\n",
      "\n",
      "sum accuracy-60.484375 sum loss-21.99098690599203\n",
      "Test batch score: 0.40105945\n",
      "Test batch accuracy: 0.90625\n",
      "47691\n",
      "\n",
      "\n",
      "sum accuracy-61.390625 sum loss-22.392046354711056\n",
      "Test batch score: 0.095184565\n",
      "Test batch accuracy: 0.953125\n",
      "47754\n",
      "\n",
      "\n",
      "sum accuracy-62.34375 sum loss-22.48723091930151\n",
      "Test batch score: 0.14105462\n",
      "Test batch accuracy: 0.9375\n",
      "47817\n",
      "\n",
      "\n",
      "sum accuracy-63.28125 sum loss-22.62828553467989\n",
      "Test batch score: 0.2682848\n",
      "Test batch accuracy: 0.90625\n",
      "47880\n",
      "\n",
      "\n",
      "sum accuracy-64.1875 sum loss-22.896570332348347\n",
      "Test batch score: 0.3314243\n",
      "Test batch accuracy: 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47943\n",
      "\n",
      "\n",
      "sum accuracy-65.078125 sum loss-23.2279946282506\n",
      "Test batch score: 0.3443877\n",
      "Test batch accuracy: 0.890625\n",
      "48006\n",
      "\n",
      "\n",
      "sum accuracy-65.96875 sum loss-23.57238233834505\n",
      "Test batch score: 0.24073246\n",
      "Test batch accuracy: 0.9375\n",
      "48069\n",
      "\n",
      "\n",
      "sum accuracy-66.90625 sum loss-23.813114799559116\n",
      "Test batch score: 0.25309783\n",
      "Test batch accuracy: 0.9375\n",
      "48132\n",
      "\n",
      "\n",
      "sum accuracy-67.84375 sum loss-24.066212631762028\n",
      "Test batch score: 0.08770242\n",
      "Test batch accuracy: 0.96875\n",
      "48195\n",
      "\n",
      "\n",
      "sum accuracy-68.8125 sum loss-24.15391505509615\n",
      "Test batch score: 0.21331003\n",
      "Test batch accuracy: 0.890625\n",
      "48258\n",
      "\n",
      "\n",
      "sum accuracy-69.703125 sum loss-24.36722508817911\n",
      "Test batch score: 0.5024294\n",
      "Test batch accuracy: 0.875\n",
      "48321\n",
      "\n",
      "\n",
      "sum accuracy-70.578125 sum loss-24.86965451389551\n",
      "Test batch score: 0.2138592\n",
      "Test batch accuracy: 0.9375\n",
      "48384\n",
      "\n",
      "\n",
      "sum accuracy-71.515625 sum loss-25.08351371437311\n",
      "Test batch score: 0.52379745\n",
      "Test batch accuracy: 0.84375\n",
      "48447\n",
      "\n",
      "\n",
      "sum accuracy-72.359375 sum loss-25.60731116682291\n",
      "Test batch score: 0.58256024\n",
      "Test batch accuracy: 0.875\n",
      "48510\n",
      "\n",
      "\n",
      "sum accuracy-73.234375 sum loss-26.189871408045292\n",
      "Test batch score: 0.3546744\n",
      "Test batch accuracy: 0.890625\n",
      "48573\n",
      "\n",
      "\n",
      "sum accuracy-74.125 sum loss-26.54454580694437\n",
      "Test batch score: 0.20281613\n",
      "Test batch accuracy: 0.921875\n",
      "48636\n",
      "\n",
      "\n",
      "sum accuracy-75.046875 sum loss-26.747361935675144\n",
      "Test batch score: 0.28984067\n",
      "Test batch accuracy: 0.953125\n",
      "48699\n",
      "\n",
      "\n",
      "sum accuracy-76.0 sum loss-27.03720260411501\n",
      "Test batch score: 0.30465457\n",
      "Test batch accuracy: 0.953125\n",
      "48762\n",
      "\n",
      "\n",
      "sum accuracy-76.953125 sum loss-27.34185717254877\n",
      "Test batch score: 0.14529106\n",
      "Test batch accuracy: 0.953125\n",
      "48825\n",
      "\n",
      "\n",
      "sum accuracy-77.90625 sum loss-27.487148232758045\n",
      "Test batch score: 0.43346673\n",
      "Test batch accuracy: 0.890625\n",
      "48888\n",
      "\n",
      "\n",
      "sum accuracy-78.796875 sum loss-27.92061496526003\n",
      "Test batch score: 0.28508502\n",
      "Test batch accuracy: 0.875\n",
      "48951\n",
      "\n",
      "\n",
      "sum accuracy-79.671875 sum loss-28.205699987709522\n",
      "Test batch score: 0.2677284\n",
      "Test batch accuracy: 0.921875\n",
      "49014\n",
      "\n",
      "\n",
      "sum accuracy-80.59375 sum loss-28.473428376019\n",
      "Test batch score: 0.4539535\n",
      "Test batch accuracy: 0.890625\n",
      "49077\n",
      "\n",
      "\n",
      "sum accuracy-81.484375 sum loss-28.92738188058138\n",
      "Test batch score: 0.40613896\n",
      "Test batch accuracy: 0.890625\n",
      "49140\n",
      "\n",
      "\n",
      "sum accuracy-82.375 sum loss-29.333520837128162\n",
      "Test batch score: 0.29432946\n",
      "Test batch accuracy: 0.921875\n",
      "49203\n",
      "\n",
      "\n",
      "sum accuracy-83.296875 sum loss-29.62785030156374\n",
      "Test batch score: 0.25879833\n",
      "Test batch accuracy: 0.90625\n",
      "49266\n",
      "\n",
      "\n",
      "sum accuracy-84.203125 sum loss-29.886648632586002\n",
      "Test batch score: 0.16672735\n",
      "Test batch accuracy: 0.953125\n",
      "49329\n",
      "\n",
      "\n",
      "sum accuracy-85.15625 sum loss-30.053375981748104\n",
      "Test batch score: 0.1836497\n",
      "Test batch accuracy: 0.9375\n",
      "49392\n",
      "\n",
      "\n",
      "sum accuracy-86.09375 sum loss-30.237025685608387\n",
      "Test batch score: 0.26523882\n",
      "Test batch accuracy: 0.9375\n",
      "49455\n",
      "\n",
      "\n",
      "sum accuracy-87.03125 sum loss-30.502264507114887\n",
      "Test batch score: 0.2906195\n",
      "Test batch accuracy: 0.9375\n",
      "49518\n",
      "\n",
      "\n",
      "sum accuracy-87.96875 sum loss-30.79288399964571\n",
      "Test batch score: 0.23442397\n",
      "Test batch accuracy: 0.921875\n",
      "49581\n",
      "\n",
      "\n",
      "sum accuracy-88.890625 sum loss-31.027307964861393\n",
      "Test batch score: 0.21095316\n",
      "Test batch accuracy: 0.9375\n",
      "49644\n",
      "\n",
      "\n",
      "sum accuracy-89.828125 sum loss-31.238261125981808\n",
      "Test batch score: 0.22066268\n",
      "Test batch accuracy: 0.9375\n",
      "49707\n",
      "\n",
      "\n",
      "sum accuracy-90.765625 sum loss-31.458923809230328\n",
      "Test batch score: 0.1843149\n",
      "Test batch accuracy: 0.953125\n",
      "49770\n",
      "\n",
      "\n",
      "sum accuracy-91.71875 sum loss-31.643238715827465\n",
      "Test batch score: 0.38935483\n",
      "Test batch accuracy: 0.90625\n",
      "49833\n",
      "\n",
      "\n",
      "sum accuracy-92.625 sum loss-32.0325935408473\n",
      "Test batch score: 0.46658805\n",
      "Test batch accuracy: 0.890625\n",
      "49896\n",
      "\n",
      "\n",
      "sum accuracy-93.515625 sum loss-32.49918159097433\n",
      "Test batch score: 0.12578917\n",
      "Test batch accuracy: 0.953125\n",
      "49959\n",
      "\n",
      "\n",
      "sum accuracy-94.46875 sum loss-32.62497075647116\n",
      "Test batch score: 0.26049495\n",
      "Test batch accuracy: 0.90625\n",
      "50022\n",
      "\n",
      "\n",
      "sum accuracy-95.375 sum loss-32.88546570390463\n",
      "Test batch score: 0.26087528\n",
      "Test batch accuracy: 0.9375\n",
      "50085\n",
      "\n",
      "\n",
      "sum accuracy-96.3125 sum loss-33.14634098857641\n",
      "Test batch score: 0.35346395\n",
      "Test batch accuracy: 0.859375\n",
      "50148\n",
      "\n",
      "\n",
      "sum accuracy-97.171875 sum loss-33.49980493634939\n",
      "Test batch score: 0.39100972\n",
      "Test batch accuracy: 0.859375\n",
      "50211\n",
      "\n",
      "\n",
      "sum accuracy-98.03125 sum loss-33.890814654529095\n",
      "Test batch score: 0.22595784\n",
      "Test batch accuracy: 0.921875\n",
      "50274\n",
      "\n",
      "\n",
      "sum accuracy-98.953125 sum loss-34.11677249521017\n",
      "Test batch score: 0.20666254\n",
      "Test batch accuracy: 0.921875\n",
      "50337\n",
      "\n",
      "\n",
      "sum accuracy-99.875 sum loss-34.32343503087759\n",
      "Test batch score: 0.2696923\n",
      "Test batch accuracy: 0.90625\n",
      "50400\n",
      "\n",
      "\n",
      "sum accuracy-100.78125 sum loss-34.59312733262777\n",
      "Test batch score: 0.23952115\n",
      "Test batch accuracy: 0.921875\n",
      "50463\n",
      "\n",
      "\n",
      "sum accuracy-101.703125 sum loss-34.83264847844839\n",
      "Test batch score: 0.5274805\n",
      "Test batch accuracy: 0.890625\n",
      "50526\n",
      "\n",
      "\n",
      "sum accuracy-102.59375 sum loss-35.360128961503506\n",
      "Test batch score: 0.33358425\n",
      "Test batch accuracy: 0.859375\n",
      "50589\n",
      "\n",
      "\n",
      "sum accuracy-103.453125 sum loss-35.69371321052313\n",
      "Test batch score: 0.4530391\n",
      "Test batch accuracy: 0.875\n",
      "50652\n",
      "\n",
      "\n",
      "sum accuracy-104.328125 sum loss-36.14675232023001\n",
      "Test batch score: 0.19672519\n",
      "Test batch accuracy: 0.921875\n",
      "50715\n",
      "\n",
      "\n",
      "sum accuracy-105.25 sum loss-36.34347750991583\n",
      "Test batch score: 0.3884217\n",
      "Test batch accuracy: 0.875\n",
      "50778\n",
      "\n",
      "\n",
      "sum accuracy-106.125 sum loss-36.731899224221706\n",
      "Test batch score: 0.3410676\n",
      "Test batch accuracy: 0.921875\n",
      "50841\n",
      "\n",
      "\n",
      "sum accuracy-107.046875 sum loss-37.07296683639288\n",
      "Test batch score: 0.5976342\n",
      "Test batch accuracy: 0.90625\n",
      "50904\n",
      "\n",
      "\n",
      "sum accuracy-107.953125 sum loss-37.67060103267431\n",
      "Test batch score: 0.14955565\n",
      "Test batch accuracy: 0.9375\n",
      "50967\n",
      "\n",
      "\n",
      "sum accuracy-108.890625 sum loss-37.82015668600798\n",
      "Test batch score: 0.27448237\n",
      "Test batch accuracy: 0.875\n",
      "51030\n",
      "\n",
      "\n",
      "sum accuracy-109.765625 sum loss-38.09463905543089\n",
      "Test batch score: 0.28305253\n",
      "Test batch accuracy: 0.9375\n",
      "51093\n",
      "\n",
      "\n",
      "sum accuracy-110.703125 sum loss-38.377691589295864\n",
      "Test batch score: 0.20030302\n",
      "Test batch accuracy: 0.921875\n",
      "51156\n",
      "\n",
      "\n",
      "sum accuracy-111.625 sum loss-38.57799460738897\n",
      "Test batch score: 0.49444336\n",
      "Test batch accuracy: 0.90625\n",
      "51219\n",
      "\n",
      "\n",
      "sum accuracy-112.53125 sum loss-39.07243796437979\n",
      "Test batch score: 0.47485414\n",
      "Test batch accuracy: 0.859375\n",
      "51282\n",
      "\n",
      "\n",
      "sum accuracy-113.390625 sum loss-39.54729210585356\n",
      "Test batch score: 0.08198072\n",
      "Test batch accuracy: 0.984375\n",
      "51345\n",
      "\n",
      "\n",
      "sum accuracy-114.375 sum loss-39.62927282601595\n",
      "Test batch score: 0.27499038\n",
      "Test batch accuracy: 0.875\n",
      "51408\n",
      "\n",
      "\n",
      "sum accuracy-115.25 sum loss-39.90426320582628\n",
      "Test batch score: 0.41087282\n",
      "Test batch accuracy: 0.890625\n",
      "51471\n",
      "\n",
      "\n",
      "sum accuracy-116.140625 sum loss-40.31513602286577\n",
      "Test batch score: 0.42761812\n",
      "Test batch accuracy: 0.875\n",
      "51534\n",
      "\n",
      "\n",
      "sum accuracy-117.015625 sum loss-40.74275413900614\n",
      "Test batch score: 0.14163116\n",
      "Test batch accuracy: 0.921875\n",
      "51597\n",
      "\n",
      "\n",
      "sum accuracy-117.9375 sum loss-40.88438529521227\n",
      "Test batch score: 0.4109916\n",
      "Test batch accuracy: 0.828125\n",
      "51660\n",
      "\n",
      "\n",
      "sum accuracy-118.765625 sum loss-41.295376904308796\n",
      "Test batch score: 0.48419255\n",
      "Test batch accuracy: 0.875\n",
      "51723\n",
      "\n",
      "\n",
      "sum accuracy-119.640625 sum loss-41.77956945449114\n",
      "Test batch score: 0.24839771\n",
      "Test batch accuracy: 0.890625\n",
      "51786\n",
      "\n",
      "\n",
      "sum accuracy-120.53125 sum loss-42.027967162430286\n",
      "Test batch score: 0.39413977\n",
      "Test batch accuracy: 0.84375\n",
      "51849\n",
      "\n",
      "\n",
      "sum accuracy-121.375 sum loss-42.4221069291234\n",
      "Test batch score: 0.27333057\n",
      "Test batch accuracy: 0.90625\n",
      "51912\n",
      "\n",
      "\n",
      "sum accuracy-122.28125 sum loss-42.695437498390675\n",
      "Test batch score: 0.28441852\n",
      "Test batch accuracy: 0.90625\n",
      "51975\n",
      "\n",
      "\n",
      "sum accuracy-123.1875 sum loss-42.97985602170229\n",
      "Test batch score: 0.28128976\n",
      "Test batch accuracy: 0.921875\n",
      "52038\n",
      "\n",
      "\n",
      "sum accuracy-124.109375 sum loss-43.261145778000355\n",
      "Test batch score: 0.34170687\n",
      "Test batch accuracy: 0.890625\n",
      "52101\n",
      "\n",
      "\n",
      "sum accuracy-125.0 sum loss-43.602852649986744\n",
      "Test batch score: 0.1838649\n",
      "Test batch accuracy: 0.9375\n",
      "52164\n",
      "\n",
      "\n",
      "sum accuracy-125.9375 sum loss-43.78671755641699\n",
      "Test batch score: 0.2049606\n",
      "Test batch accuracy: 0.96875\n",
      "52227\n",
      "\n",
      "\n",
      "sum accuracy-126.90625 sum loss-43.99167815595865\n",
      "Test batch score: 0.32842815\n",
      "Test batch accuracy: 0.90625\n",
      "52290\n",
      "\n",
      "\n",
      "sum accuracy-127.8125 sum loss-44.32010630518198\n",
      "Test batch score: 0.41508785\n",
      "Test batch accuracy: 0.890625\n",
      "52353\n",
      "\n",
      "\n",
      "sum accuracy-128.703125 sum loss-44.73519415408373\n",
      "Test batch score: 0.4184399\n",
      "Test batch accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52416\n",
      "\n",
      "\n",
      "sum accuracy-129.578125 sum loss-45.153634048998356\n",
      "Test batch score: 0.25488672\n",
      "Test batch accuracy: 0.890625\n",
      "52479\n",
      "\n",
      "\n",
      "sum accuracy-130.46875 sum loss-45.40852076560259\n",
      "Test batch score: 0.16453198\n",
      "Test batch accuracy: 0.890625\n",
      "52542\n",
      "\n",
      "\n",
      "sum accuracy-131.359375 sum loss-45.57305274158716\n",
      "Test batch score: 0.25058487\n",
      "Test batch accuracy: 0.90625\n",
      "52605\n",
      "\n",
      "\n",
      "sum accuracy-132.265625 sum loss-45.82363761216402\n",
      "Test batch score: 0.17122534\n",
      "Test batch accuracy: 0.921875\n",
      "52668\n",
      "\n",
      "\n",
      "sum accuracy-133.1875 sum loss-45.99486295133829\n",
      "Test batch score: 0.241408\n",
      "Test batch accuracy: 0.921875\n",
      "52731\n",
      "\n",
      "\n",
      "sum accuracy-134.109375 sum loss-46.23627095669508\n",
      "Test batch score: 0.12563272\n",
      "Test batch accuracy: 0.953125\n",
      "52794\n",
      "\n",
      "\n",
      "sum accuracy-135.0625 sum loss-46.36190367490053\n",
      "Test batch score: 0.18046378\n",
      "Test batch accuracy: 0.921875\n",
      "52857\n",
      "\n",
      "\n",
      "sum accuracy-135.984375 sum loss-46.542367450892925\n",
      "Test batch score: 0.32706317\n",
      "Test batch accuracy: 0.921875\n",
      "52920\n",
      "\n",
      "\n",
      "sum accuracy-136.90625 sum loss-46.869430623948574\n",
      "Test batch score: 0.17472734\n",
      "Test batch accuracy: 0.96875\n",
      "52983\n",
      "\n",
      "\n",
      "sum accuracy-137.875 sum loss-47.04415795952082\n",
      "Test batch score: 0.23356688\n",
      "Test batch accuracy: 0.953125\n",
      "53046\n",
      "\n",
      "\n",
      "sum accuracy-138.828125 sum loss-47.27772483974695\n",
      "Test batch score: 0.28499737\n",
      "Test batch accuracy: 0.953125\n",
      "53109\n",
      "\n",
      "\n",
      "sum accuracy-139.78125 sum loss-47.5627222135663\n",
      "Test batch score: 0.43216228\n",
      "Test batch accuracy: 0.875\n",
      "53172\n",
      "\n",
      "\n",
      "sum accuracy-140.65625 sum loss-47.99488449841738\n",
      "Test batch score: 0.19479492\n",
      "Test batch accuracy: 0.96875\n",
      "53235\n",
      "\n",
      "\n",
      "sum accuracy-141.625 sum loss-48.18967942148447\n",
      "Test batch score: 0.62205637\n",
      "Test batch accuracy: 0.828125\n",
      "53298\n",
      "\n",
      "\n",
      "sum accuracy-142.453125 sum loss-48.81173578649759\n",
      "Test batch score: 0.09741982\n",
      "Test batch accuracy: 0.96875\n",
      "53361\n",
      "\n",
      "\n",
      "sum accuracy-143.421875 sum loss-48.90915560722351\n",
      "Test batch score: 0.31965476\n",
      "Test batch accuracy: 0.90625\n",
      "53424\n",
      "\n",
      "\n",
      "sum accuracy-144.328125 sum loss-49.228810369968414\n",
      "Test batch score: 0.29858768\n",
      "Test batch accuracy: 0.921875\n",
      "53487\n",
      "\n",
      "\n",
      "sum accuracy-145.25 sum loss-49.52739804983139\n",
      "Test batch score: 0.11717825\n",
      "Test batch accuracy: 0.953125\n",
      "53550\n",
      "\n",
      "\n",
      "sum accuracy-146.203125 sum loss-49.64457629621029\n",
      "Test batch score: 0.22828302\n",
      "Test batch accuracy: 0.90625\n",
      "53613\n",
      "\n",
      "\n",
      "sum accuracy-147.109375 sum loss-49.87285931408405\n",
      "Test batch score: 0.32143864\n",
      "Test batch accuracy: 0.859375\n",
      "53676\n",
      "\n",
      "\n",
      "sum accuracy-147.96875 sum loss-50.19429795444012\n",
      "Test batch score: 0.45926735\n",
      "Test batch accuracy: 0.890625\n",
      "53739\n",
      "\n",
      "\n",
      "sum accuracy-148.859375 sum loss-50.65356530249119\n",
      "Test batch score: 0.33713073\n",
      "Test batch accuracy: 0.90625\n",
      "53802\n",
      "\n",
      "\n",
      "sum accuracy-149.765625 sum loss-50.99069602787495\n",
      "Test batch score: 0.5918722\n",
      "Test batch accuracy: 0.84375\n",
      "53865\n",
      "\n",
      "\n",
      "sum accuracy-150.609375 sum loss-51.58256824314594\n",
      "Test batch score: 0.45070428\n",
      "Test batch accuracy: 0.828125\n",
      "53928\n",
      "\n",
      "\n",
      "sum accuracy-151.4375 sum loss-52.03327251970768\n",
      "Test batch score: 0.5854701\n",
      "Test batch accuracy: 0.890625\n",
      "53991\n",
      "\n",
      "\n",
      "sum accuracy-152.328125 sum loss-52.61874260008335\n",
      "Test batch score: 0.21476528\n",
      "Test batch accuracy: 0.953125\n",
      "54054\n",
      "\n",
      "\n",
      "sum accuracy-153.28125 sum loss-52.833507880568504\n",
      "Test batch score: 0.18776655\n",
      "Test batch accuracy: 0.96875\n",
      "54117\n",
      "\n",
      "\n",
      "sum accuracy-154.25 sum loss-53.02127443253994\n",
      "Test batch score: 0.4266866\n",
      "Test batch accuracy: 0.875\n",
      "54180\n",
      "\n",
      "\n",
      "sum accuracy-155.125 sum loss-53.447961047291756\n",
      "Test batch score: 0.39147604\n",
      "Test batch accuracy: 0.921875\n",
      "54243\n",
      "\n",
      "\n",
      "sum accuracy-156.046875 sum loss-53.83943708240986\n"
     ]
    }
   ],
   "source": [
    "current_index = 43407\n",
    "loss = 0.0\n",
    "acc = 0.0\n",
    "\n",
    "while current_index + batch_size < len(image_data_list):\n",
    "    b, l = get_batch()\n",
    "\n",
    "    score = customVggModel.test_on_batch(b, l)\n",
    "    print('Test batch score:', score[0])\n",
    "    print('Test batch accuracy:', score[1], flush = True)\n",
    "    print(current_index)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    loss += score[0]\n",
    "    acc += score[1]\n",
    "    print(\"sum accuracy-{} sum loss-{}\".format(acc,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "848\n",
      "156.046875\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "temp = int((0.2*len(image_data_list))/(batch_size))\n",
    "print(temp)\n",
    "print(math.ceil(nice_n / batch_size))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3185765507834903\n",
      "Test accuracy: 0.1840175412735849\n"
     ]
    }
   ],
   "source": [
    "loss = loss / temp\n",
    "acc = acc / temp\n",
    "\n",
    "print('Test score:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9233542899408284\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9233542899408284\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = os.getcwd()\n",
    "# # data_path = path + '/raw/color'\n",
    "# # #train_data_file = path + '/data_distribution_for_SVM/train_mapping.txt'\n",
    "\n",
    "# data_path = path + '/data_distribution_for_SVM/train'\n",
    "# train_data_file = path + '/data_distribution_for_SVM/train_mapping.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map_dict = {}\n",
    "# image_data_list = []\n",
    "# labels = []\n",
    "# i = 0\n",
    "\n",
    "# # for filename in os.listdir(data_path) :\n",
    "# #     text_filename = filename.strip()\n",
    "# #     for imagename in os.listdir(data_path + '/' + filename) :\n",
    "# #         img_path = data_path + '/' + filename + '/' + imagename\n",
    "# #         img = image.load_img(img_path, target_size=(224,224))\n",
    "# #         x = image.img_to_array(img)\n",
    "# #         x = np.expand_dims(x, axis = 0)\n",
    "# #         x = preprocess_input(x)\n",
    "# #         image_data_list.append(x)\n",
    "    \n",
    "# #     labels.append(i)\n",
    "# #     if i not in label_map_dict :\n",
    "# #         label_map_dict[i] = text_filename\n",
    "# #     i += 1\n",
    "\n",
    "# with open(train_data_file) as f:\n",
    "#     for line in f :\n",
    "#         words = line.split('/')\n",
    "#         length = len(words)\n",
    "#         labels.append(words[length-2])\n",
    "#         if words[length-2] not in label_map_dict :\n",
    "#             label_map_dict[length-2] = words[2]\n",
    "            \n",
    "#         words[length-1] = words[length-1].strip('\\n')     \n",
    "#         img_path = data_path + '/' + words[length-2] + '/' + words[length-1]\n",
    "#         img = image.load_img(img_path, target_size=(224,224))\n",
    "#         x = image.img_to_array(img)\n",
    "#         x = np.expand_dims(x, axis = 0)\n",
    "#         x = preprocess_input(x)\n",
    "#         image_data_list.append(x)\n",
    "\n",
    "# print(image_data_list.shape)\n",
    "# img_data = np.array(image_data_list)\n",
    "# print (img_data.shape)\n",
    "# img_data=np.rollaxis(img_data,1,0)\n",
    "# print (img_data.shape)\n",
    "# img_data=img_data[0]\n",
    "# print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
